{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate Poem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uLX9a9UGrUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "fafa4e54-70b1-4354-bfc1-8281d09d8451"
      },
      "source": [
        "!wget https://github.com/lazyprogrammer/machine_learning_examples/raw/master/hmm_class/robert_frost.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-07 10:06:01--  https://github.com/lazyprogrammer/machine_learning_examples/raw/master/hmm_class/robert_frost.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt [following]\n",
            "--2020-02-07 10:06:01--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "\rrobert_frost.txt      0%[                    ]       0  --.-KB/s               \rrobert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-02-07 10:06:02 (2.70 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w03kNvjnGr4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6957e94c-de9c-4512-bcd1-4f409be12475"
      },
      "source": [
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-07 10:06:14--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-02-07 10:06:14--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-02-07 10:06:14--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.10MB/s    in 6m 27s  \n",
            "\n",
            "2020-02-07 10:12:41 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3UPnEHRG2sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"glove.6B.zip\", 'r')\n",
        "zip_ref.extractall(\"glove vectors\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH2knjrgGlIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "75b9567d-f247-497c-ed77-14343dbefb0b"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "import keras.backend as K\n",
        "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "  from keras.layers import CuDNNLSTM as LSTM\n",
        "  from keras.layers import CuDNNGRU as GRU\n",
        "\n",
        "\n",
        "# some configuration\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_VOCAB_SIZE = 3000\n",
        "EMBEDDING_DIM = 50\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 1000\n",
        "LATENT_DIM = 25\n",
        "\n",
        "# load in the data\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "for line in open('robert_frost.txt'):\n",
        "  line = line.rstrip()\n",
        "  if not line:\n",
        "    continue\n",
        "\n",
        "  input_line = '<sos> ' + line\n",
        "  target_line = line + ' <eos>'\n",
        "\n",
        "  input_texts.append(input_line)\n",
        "  target_texts.append(target_line)\n",
        "\n",
        "\n",
        "all_lines = input_texts + target_texts\n",
        "\n",
        "# convert the sentences (strings) into integers\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
        "tokenizer.fit_on_texts(all_lines)\n",
        "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "# find max seq length\n",
        "max_sequence_length_from_data = max(len(s) for s in input_sequences)\n",
        "print('Max sequence length:', max_sequence_length_from_data)\n",
        "\n",
        "\n",
        "# get word -> integer mapping\n",
        "word2idx = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word2idx))\n",
        "assert('<sos>' in word2idx)\n",
        "assert('<eos>' in word2idx)\n",
        "\n",
        "\n",
        "# pad sequences so that we get a N x T matrix\n",
        "max_sequence_length = min(max_sequence_length_from_data, MAX_SEQUENCE_LENGTH)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n",
        "print('Shape of data tensor:', input_sequences.shape)\n",
        "\n",
        "\n",
        "\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open('/content/glove vectors/glove.6B.50d.txt') as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\n",
        "\n",
        "\n",
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx.items():\n",
        "  if i < MAX_VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n",
        "# one-hot the targets (can't use sparse cross-entropy)\n",
        "one_hot_targets = np.zeros((len(input_sequences), max_sequence_length, num_words))\n",
        "for i, target_sequence in enumerate(target_sequences):\n",
        "  for t, word in enumerate(target_sequence):\n",
        "    if word > 0:\n",
        "      one_hot_targets[i, t, word] = 1\n",
        "\n",
        "\n",
        "\n",
        "# load pre-trained word embeddings into an Embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  # trainable=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print('Building model...')\n",
        "\n",
        "# create an LSTM network with a single LSTM\n",
        "input_ = Input(shape=(max_sequence_length,))\n",
        "initial_h = Input(shape=(LATENT_DIM,))\n",
        "initial_c = Input(shape=(LATENT_DIM,))\n",
        "x = embedding_layer(input_)\n",
        "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
        "x, _, _ = lstm(x, initial_state=[initial_h, initial_c]) # don't need the states here\n",
        "dense = Dense(num_words, activation='softmax')\n",
        "output = dense(x)\n",
        "\n",
        "model = Model([input_, initial_h, initial_c], output)\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  # optimizer='rmsprop',\n",
        "  optimizer=Adam(lr=0.01),\n",
        "  # optimizer=SGD(lr=0.01, momentum=0.9),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length: 12\n",
            "Found 3056 unique tokens.\n",
            "Shape of data tensor: (1436, 12)\n",
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n",
            "Filling pre-trained embeddings...\n",
            "Building model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-AhYGCPxA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db8574ce-5d46-45f3-c2ee-84fa96098354"
      },
      "source": [
        "print('Training model...')\n",
        "z = np.zeros((len(input_sequences), LATENT_DIM))\n",
        "r = model.fit(\n",
        "  [input_sequences, z, z],\n",
        "  one_hot_targets,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=VALIDATION_SPLIT\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "Train on 1148 samples, validate on 288 samples\n",
            "Epoch 1/1000\n",
            "1148/1148 [==============================] - 1s 879us/step - loss: 5.3877 - acc: 0.0665 - val_loss: 5.0509 - val_acc: 0.0836\n",
            "Epoch 2/1000\n",
            "1148/1148 [==============================] - 0s 348us/step - loss: 4.6308 - acc: 0.0844 - val_loss: 4.8190 - val_acc: 0.0833\n",
            "Epoch 3/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 4.3790 - acc: 0.0833 - val_loss: 4.9336 - val_acc: 0.0833\n",
            "Epoch 4/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 4.3347 - acc: 0.0833 - val_loss: 4.9549 - val_acc: 0.0833\n",
            "Epoch 5/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 4.2898 - acc: 0.0833 - val_loss: 4.9844 - val_acc: 0.0833\n",
            "Epoch 6/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 4.2524 - acc: 0.0833 - val_loss: 4.9490 - val_acc: 0.0833\n",
            "Epoch 7/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 4.1952 - acc: 0.0833 - val_loss: 4.8804 - val_acc: 0.0833\n",
            "Epoch 8/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 4.1401 - acc: 0.0833 - val_loss: 4.8501 - val_acc: 0.0833\n",
            "Epoch 9/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 4.0834 - acc: 0.0833 - val_loss: 4.8311 - val_acc: 0.0833\n",
            "Epoch 10/1000\n",
            "1148/1148 [==============================] - 0s 339us/step - loss: 4.0324 - acc: 0.0833 - val_loss: 4.8144 - val_acc: 0.0833\n",
            "Epoch 11/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 3.9843 - acc: 0.0836 - val_loss: 4.8165 - val_acc: 0.0836\n",
            "Epoch 12/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 3.9407 - acc: 0.0867 - val_loss: 4.8066 - val_acc: 0.0854\n",
            "Epoch 13/1000\n",
            "1148/1148 [==============================] - 0s 341us/step - loss: 3.9014 - acc: 0.0926 - val_loss: 4.8129 - val_acc: 0.0894\n",
            "Epoch 14/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 3.8613 - acc: 0.0986 - val_loss: 4.8156 - val_acc: 0.0891\n",
            "Epoch 15/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 3.8223 - acc: 0.1006 - val_loss: 4.8194 - val_acc: 0.0880\n",
            "Epoch 16/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 3.7830 - acc: 0.1034 - val_loss: 4.8229 - val_acc: 0.0891\n",
            "Epoch 17/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 3.7366 - acc: 0.1074 - val_loss: 4.8076 - val_acc: 0.0938\n",
            "Epoch 18/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 3.6871 - acc: 0.1167 - val_loss: 4.8102 - val_acc: 0.0932\n",
            "Epoch 19/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 3.6434 - acc: 0.1190 - val_loss: 4.8181 - val_acc: 0.0938\n",
            "Epoch 20/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 3.6021 - acc: 0.1207 - val_loss: 4.8147 - val_acc: 0.0938\n",
            "Epoch 21/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 3.5617 - acc: 0.1225 - val_loss: 4.8256 - val_acc: 0.0935\n",
            "Epoch 22/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 3.5242 - acc: 0.1234 - val_loss: 4.8314 - val_acc: 0.0926\n",
            "Epoch 23/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 3.4876 - acc: 0.1239 - val_loss: 4.8352 - val_acc: 0.0932\n",
            "Epoch 24/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 3.4529 - acc: 0.1259 - val_loss: 4.8421 - val_acc: 0.0935\n",
            "Epoch 25/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 3.4196 - acc: 0.1275 - val_loss: 4.8500 - val_acc: 0.0940\n",
            "Epoch 26/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 3.3861 - acc: 0.1294 - val_loss: 4.8561 - val_acc: 0.0961\n",
            "Epoch 27/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 3.3537 - acc: 0.1316 - val_loss: 4.8670 - val_acc: 0.0958\n",
            "Epoch 28/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 3.3213 - acc: 0.1341 - val_loss: 4.8732 - val_acc: 0.0964\n",
            "Epoch 29/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 3.2894 - acc: 0.1355 - val_loss: 4.8841 - val_acc: 0.0972\n",
            "Epoch 30/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 3.2598 - acc: 0.1382 - val_loss: 4.8903 - val_acc: 0.0978\n",
            "Epoch 31/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 3.2291 - acc: 0.1417 - val_loss: 4.9036 - val_acc: 0.1004\n",
            "Epoch 32/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 3.1994 - acc: 0.1428 - val_loss: 4.9112 - val_acc: 0.0987\n",
            "Epoch 33/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 3.1696 - acc: 0.1487 - val_loss: 4.9259 - val_acc: 0.0995\n",
            "Epoch 34/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 3.1417 - acc: 0.1492 - val_loss: 4.9346 - val_acc: 0.0992\n",
            "Epoch 35/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 3.1145 - acc: 0.1537 - val_loss: 4.9375 - val_acc: 0.1010\n",
            "Epoch 36/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 3.0862 - acc: 0.1545 - val_loss: 4.9479 - val_acc: 0.0995\n",
            "Epoch 37/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 3.0578 - acc: 0.1569 - val_loss: 4.9618 - val_acc: 0.1019\n",
            "Epoch 38/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 3.0310 - acc: 0.1585 - val_loss: 4.9671 - val_acc: 0.0998\n",
            "Epoch 39/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 3.0037 - acc: 0.1627 - val_loss: 4.9826 - val_acc: 0.1001\n",
            "Epoch 40/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 2.9778 - acc: 0.1654 - val_loss: 4.9885 - val_acc: 0.1001\n",
            "Epoch 41/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 2.9498 - acc: 0.1693 - val_loss: 5.0010 - val_acc: 0.1013\n",
            "Epoch 42/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 2.9248 - acc: 0.1741 - val_loss: 5.0127 - val_acc: 0.1021\n",
            "Epoch 43/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 2.8973 - acc: 0.1750 - val_loss: 5.0177 - val_acc: 0.1024\n",
            "Epoch 44/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 2.8724 - acc: 0.1784 - val_loss: 5.0311 - val_acc: 0.1021\n",
            "Epoch 45/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 2.8469 - acc: 0.1816 - val_loss: 5.0406 - val_acc: 0.1019\n",
            "Epoch 46/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 2.8213 - acc: 0.1839 - val_loss: 5.0541 - val_acc: 0.1030\n",
            "Epoch 47/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 2.7975 - acc: 0.1879 - val_loss: 5.0626 - val_acc: 0.1016\n",
            "Epoch 48/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 2.7725 - acc: 0.1916 - val_loss: 5.0723 - val_acc: 0.1027\n",
            "Epoch 49/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 2.7492 - acc: 0.1938 - val_loss: 5.0837 - val_acc: 0.1027\n",
            "Epoch 50/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 2.7263 - acc: 0.1975 - val_loss: 5.0961 - val_acc: 0.1010\n",
            "Epoch 51/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 2.7041 - acc: 0.1989 - val_loss: 5.1077 - val_acc: 0.1001\n",
            "Epoch 52/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 2.6814 - acc: 0.2021 - val_loss: 5.1181 - val_acc: 0.0995\n",
            "Epoch 53/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 2.6606 - acc: 0.2046 - val_loss: 5.1287 - val_acc: 0.0998\n",
            "Epoch 54/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 2.6385 - acc: 0.2093 - val_loss: 5.1439 - val_acc: 0.0995\n",
            "Epoch 55/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 2.6176 - acc: 0.2119 - val_loss: 5.1514 - val_acc: 0.0981\n",
            "Epoch 56/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 2.5959 - acc: 0.2136 - val_loss: 5.1622 - val_acc: 0.0978\n",
            "Epoch 57/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 2.5766 - acc: 0.2160 - val_loss: 5.1751 - val_acc: 0.0966\n",
            "Epoch 58/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 2.5554 - acc: 0.2192 - val_loss: 5.1901 - val_acc: 0.0961\n",
            "Epoch 59/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 2.5359 - acc: 0.2219 - val_loss: 5.2000 - val_acc: 0.0958\n",
            "Epoch 60/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.5150 - acc: 0.2255 - val_loss: 5.2131 - val_acc: 0.0969\n",
            "Epoch 61/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 2.4959 - acc: 0.2270 - val_loss: 5.2214 - val_acc: 0.0964\n",
            "Epoch 62/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 2.4775 - acc: 0.2294 - val_loss: 5.2358 - val_acc: 0.0943\n",
            "Epoch 63/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 2.4594 - acc: 0.2318 - val_loss: 5.2493 - val_acc: 0.0952\n",
            "Epoch 64/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.4413 - acc: 0.2351 - val_loss: 5.2537 - val_acc: 0.0935\n",
            "Epoch 65/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 2.4246 - acc: 0.2378 - val_loss: 5.2659 - val_acc: 0.0938\n",
            "Epoch 66/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 2.4080 - acc: 0.2389 - val_loss: 5.2747 - val_acc: 0.0946\n",
            "Epoch 67/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 2.3910 - acc: 0.2390 - val_loss: 5.2898 - val_acc: 0.0943\n",
            "Epoch 68/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 2.3752 - acc: 0.2430 - val_loss: 5.3021 - val_acc: 0.0946\n",
            "Epoch 69/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 2.3592 - acc: 0.2447 - val_loss: 5.3150 - val_acc: 0.0932\n",
            "Epoch 70/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 2.3417 - acc: 0.2462 - val_loss: 5.3233 - val_acc: 0.0955\n",
            "Epoch 71/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 2.3250 - acc: 0.2485 - val_loss: 5.3344 - val_acc: 0.0943\n",
            "Epoch 72/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 2.3086 - acc: 0.2505 - val_loss: 5.3431 - val_acc: 0.0932\n",
            "Epoch 73/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 2.2940 - acc: 0.2513 - val_loss: 5.3523 - val_acc: 0.0929\n",
            "Epoch 74/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 2.2777 - acc: 0.2544 - val_loss: 5.3590 - val_acc: 0.0935\n",
            "Epoch 75/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 2.2633 - acc: 0.2566 - val_loss: 5.3701 - val_acc: 0.0914\n",
            "Epoch 76/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 2.2500 - acc: 0.2579 - val_loss: 5.3796 - val_acc: 0.0935\n",
            "Epoch 77/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 2.2356 - acc: 0.2609 - val_loss: 5.3920 - val_acc: 0.0932\n",
            "Epoch 78/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 2.2220 - acc: 0.2630 - val_loss: 5.4020 - val_acc: 0.0917\n",
            "Epoch 79/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 2.2087 - acc: 0.2637 - val_loss: 5.4074 - val_acc: 0.0938\n",
            "Epoch 80/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.1940 - acc: 0.2658 - val_loss: 5.4194 - val_acc: 0.0917\n",
            "Epoch 81/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 2.1803 - acc: 0.2674 - val_loss: 5.4251 - val_acc: 0.0917\n",
            "Epoch 82/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 2.1682 - acc: 0.2693 - val_loss: 5.4391 - val_acc: 0.0917\n",
            "Epoch 83/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.1554 - acc: 0.2704 - val_loss: 5.4511 - val_acc: 0.0914\n",
            "Epoch 84/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 2.1440 - acc: 0.2716 - val_loss: 5.4618 - val_acc: 0.0911\n",
            "Epoch 85/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.1315 - acc: 0.2734 - val_loss: 5.4634 - val_acc: 0.0926\n",
            "Epoch 86/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 2.1205 - acc: 0.2766 - val_loss: 5.4746 - val_acc: 0.0914\n",
            "Epoch 87/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 2.1119 - acc: 0.2770 - val_loss: 5.4849 - val_acc: 0.0914\n",
            "Epoch 88/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 2.0999 - acc: 0.2777 - val_loss: 5.4993 - val_acc: 0.0900\n",
            "Epoch 89/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 2.0880 - acc: 0.2795 - val_loss: 5.5084 - val_acc: 0.0917\n",
            "Epoch 90/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 2.0763 - acc: 0.2814 - val_loss: 5.5109 - val_acc: 0.0914\n",
            "Epoch 91/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 2.0648 - acc: 0.2829 - val_loss: 5.5227 - val_acc: 0.0914\n",
            "Epoch 92/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 2.0520 - acc: 0.2848 - val_loss: 5.5328 - val_acc: 0.0920\n",
            "Epoch 93/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 2.0395 - acc: 0.2861 - val_loss: 5.5457 - val_acc: 0.0888\n",
            "Epoch 94/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 2.0283 - acc: 0.2875 - val_loss: 5.5490 - val_acc: 0.0897\n",
            "Epoch 95/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 2.0184 - acc: 0.2891 - val_loss: 5.5629 - val_acc: 0.0906\n",
            "Epoch 96/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 2.0068 - acc: 0.2905 - val_loss: 5.5663 - val_acc: 0.0897\n",
            "Epoch 97/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.9959 - acc: 0.2922 - val_loss: 5.5764 - val_acc: 0.0909\n",
            "Epoch 98/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.9855 - acc: 0.2944 - val_loss: 5.5849 - val_acc: 0.0897\n",
            "Epoch 99/1000\n",
            "1148/1148 [==============================] - 0s 336us/step - loss: 1.9736 - acc: 0.2959 - val_loss: 5.5920 - val_acc: 0.0909\n",
            "Epoch 100/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.9631 - acc: 0.2981 - val_loss: 5.6013 - val_acc: 0.0903\n",
            "Epoch 101/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.9546 - acc: 0.2991 - val_loss: 5.6103 - val_acc: 0.0894\n",
            "Epoch 102/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.9446 - acc: 0.3001 - val_loss: 5.6229 - val_acc: 0.0894\n",
            "Epoch 103/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.9359 - acc: 0.3024 - val_loss: 5.6296 - val_acc: 0.0906\n",
            "Epoch 104/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.9268 - acc: 0.3043 - val_loss: 5.6382 - val_acc: 0.0894\n",
            "Epoch 105/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.9178 - acc: 0.3030 - val_loss: 5.6502 - val_acc: 0.0891\n",
            "Epoch 106/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.9083 - acc: 0.3044 - val_loss: 5.6580 - val_acc: 0.0891\n",
            "Epoch 107/1000\n",
            "1148/1148 [==============================] - 0s 360us/step - loss: 1.9010 - acc: 0.3063 - val_loss: 5.6686 - val_acc: 0.0888\n",
            "Epoch 108/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.8932 - acc: 0.3081 - val_loss: 5.6760 - val_acc: 0.0880\n",
            "Epoch 109/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 1.8853 - acc: 0.3093 - val_loss: 5.6856 - val_acc: 0.0871\n",
            "Epoch 110/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.8757 - acc: 0.3102 - val_loss: 5.6911 - val_acc: 0.0865\n",
            "Epoch 111/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.8654 - acc: 0.3125 - val_loss: 5.7041 - val_acc: 0.0871\n",
            "Epoch 112/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.8581 - acc: 0.3132 - val_loss: 5.7088 - val_acc: 0.0868\n",
            "Epoch 113/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.8495 - acc: 0.3132 - val_loss: 5.7245 - val_acc: 0.0885\n",
            "Epoch 114/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.8411 - acc: 0.3166 - val_loss: 5.7311 - val_acc: 0.0859\n",
            "Epoch 115/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.8321 - acc: 0.3177 - val_loss: 5.7345 - val_acc: 0.0859\n",
            "Epoch 116/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.8248 - acc: 0.3186 - val_loss: 5.7490 - val_acc: 0.0868\n",
            "Epoch 117/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.8162 - acc: 0.3218 - val_loss: 5.7564 - val_acc: 0.0851\n",
            "Epoch 118/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.8071 - acc: 0.3224 - val_loss: 5.7633 - val_acc: 0.0856\n",
            "Epoch 119/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.7986 - acc: 0.3230 - val_loss: 5.7687 - val_acc: 0.0845\n",
            "Epoch 120/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.7907 - acc: 0.3247 - val_loss: 5.7767 - val_acc: 0.0856\n",
            "Epoch 121/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.7826 - acc: 0.3245 - val_loss: 5.7823 - val_acc: 0.0848\n",
            "Epoch 122/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.7743 - acc: 0.3274 - val_loss: 5.7940 - val_acc: 0.0848\n",
            "Epoch 123/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.7685 - acc: 0.3290 - val_loss: 5.7958 - val_acc: 0.0830\n",
            "Epoch 124/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.7602 - acc: 0.3292 - val_loss: 5.7980 - val_acc: 0.0845\n",
            "Epoch 125/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.7533 - acc: 0.3309 - val_loss: 5.8119 - val_acc: 0.0836\n",
            "Epoch 126/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.7445 - acc: 0.3324 - val_loss: 5.8189 - val_acc: 0.0848\n",
            "Epoch 127/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.7374 - acc: 0.3345 - val_loss: 5.8322 - val_acc: 0.0830\n",
            "Epoch 128/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.7324 - acc: 0.3320 - val_loss: 5.8291 - val_acc: 0.0839\n",
            "Epoch 129/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.7238 - acc: 0.3375 - val_loss: 5.8478 - val_acc: 0.0828\n",
            "Epoch 130/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.7164 - acc: 0.3381 - val_loss: 5.8516 - val_acc: 0.0833\n",
            "Epoch 131/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.7094 - acc: 0.3394 - val_loss: 5.8594 - val_acc: 0.0828\n",
            "Epoch 132/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.7011 - acc: 0.3410 - val_loss: 5.8735 - val_acc: 0.0804\n",
            "Epoch 133/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.6938 - acc: 0.3415 - val_loss: 5.8795 - val_acc: 0.0810\n",
            "Epoch 134/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.6881 - acc: 0.3418 - val_loss: 5.8875 - val_acc: 0.0810\n",
            "Epoch 135/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 1.6815 - acc: 0.3444 - val_loss: 5.8981 - val_acc: 0.0839\n",
            "Epoch 136/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.6750 - acc: 0.3447 - val_loss: 5.9095 - val_acc: 0.0828\n",
            "Epoch 137/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.6684 - acc: 0.3449 - val_loss: 5.9168 - val_acc: 0.0822\n",
            "Epoch 138/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.6623 - acc: 0.3479 - val_loss: 5.9182 - val_acc: 0.0813\n",
            "Epoch 139/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.6550 - acc: 0.3489 - val_loss: 5.9328 - val_acc: 0.0807\n",
            "Epoch 140/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.6501 - acc: 0.3505 - val_loss: 5.9355 - val_acc: 0.0822\n",
            "Epoch 141/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.6458 - acc: 0.3511 - val_loss: 5.9436 - val_acc: 0.0822\n",
            "Epoch 142/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.6368 - acc: 0.3535 - val_loss: 5.9578 - val_acc: 0.0802\n",
            "Epoch 143/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.6304 - acc: 0.3523 - val_loss: 5.9540 - val_acc: 0.0810\n",
            "Epoch 144/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.6229 - acc: 0.3537 - val_loss: 5.9740 - val_acc: 0.0804\n",
            "Epoch 145/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.6168 - acc: 0.3566 - val_loss: 5.9780 - val_acc: 0.0813\n",
            "Epoch 146/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.6121 - acc: 0.3572 - val_loss: 5.9827 - val_acc: 0.0816\n",
            "Epoch 147/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.6060 - acc: 0.3593 - val_loss: 5.9952 - val_acc: 0.0802\n",
            "Epoch 148/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.5992 - acc: 0.3585 - val_loss: 5.9948 - val_acc: 0.0807\n",
            "Epoch 149/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.5940 - acc: 0.3608 - val_loss: 6.0062 - val_acc: 0.0799\n",
            "Epoch 150/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.5889 - acc: 0.3608 - val_loss: 6.0026 - val_acc: 0.0819\n",
            "Epoch 151/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.5853 - acc: 0.3614 - val_loss: 6.0138 - val_acc: 0.0819\n",
            "Epoch 152/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.5807 - acc: 0.3640 - val_loss: 6.0243 - val_acc: 0.0816\n",
            "Epoch 153/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.5737 - acc: 0.3636 - val_loss: 6.0298 - val_acc: 0.0804\n",
            "Epoch 154/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.5662 - acc: 0.3667 - val_loss: 6.0439 - val_acc: 0.0802\n",
            "Epoch 155/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.5595 - acc: 0.3664 - val_loss: 6.0439 - val_acc: 0.0810\n",
            "Epoch 156/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.5540 - acc: 0.3686 - val_loss: 6.0520 - val_acc: 0.0799\n",
            "Epoch 157/1000\n",
            "1148/1148 [==============================] - 0s 337us/step - loss: 1.5494 - acc: 0.3694 - val_loss: 6.0651 - val_acc: 0.0802\n",
            "Epoch 158/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.5437 - acc: 0.3692 - val_loss: 6.0673 - val_acc: 0.0804\n",
            "Epoch 159/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.5389 - acc: 0.3704 - val_loss: 6.0796 - val_acc: 0.0822\n",
            "Epoch 160/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.5353 - acc: 0.3704 - val_loss: 6.0767 - val_acc: 0.0796\n",
            "Epoch 161/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.5291 - acc: 0.3730 - val_loss: 6.0897 - val_acc: 0.0804\n",
            "Epoch 162/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.5247 - acc: 0.3736 - val_loss: 6.0896 - val_acc: 0.0802\n",
            "Epoch 163/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.5197 - acc: 0.3751 - val_loss: 6.0939 - val_acc: 0.0799\n",
            "Epoch 164/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 6.1076 - val_acc: 0.0819\n",
            "Epoch 165/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.5184 - acc: 0.3735 - val_loss: 6.1045 - val_acc: 0.0804\n",
            "Epoch 166/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.5103 - acc: 0.3743 - val_loss: 6.1137 - val_acc: 0.0799\n",
            "Epoch 167/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.5009 - acc: 0.3769 - val_loss: 6.1184 - val_acc: 0.0807\n",
            "Epoch 168/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.4942 - acc: 0.3787 - val_loss: 6.1247 - val_acc: 0.0804\n",
            "Epoch 169/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.4886 - acc: 0.3812 - val_loss: 6.1278 - val_acc: 0.0796\n",
            "Epoch 170/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.4820 - acc: 0.3825 - val_loss: 6.1360 - val_acc: 0.0793\n",
            "Epoch 171/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.4781 - acc: 0.3831 - val_loss: 6.1470 - val_acc: 0.0813\n",
            "Epoch 172/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.4738 - acc: 0.3839 - val_loss: 6.1499 - val_acc: 0.0816\n",
            "Epoch 173/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.4689 - acc: 0.3869 - val_loss: 6.1604 - val_acc: 0.0810\n",
            "Epoch 174/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.4639 - acc: 0.3877 - val_loss: 6.1630 - val_acc: 0.0804\n",
            "Epoch 175/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.4594 - acc: 0.3885 - val_loss: 6.1705 - val_acc: 0.0807\n",
            "Epoch 176/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.4550 - acc: 0.3883 - val_loss: 6.1776 - val_acc: 0.0804\n",
            "Epoch 177/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 1.4499 - acc: 0.3896 - val_loss: 6.1818 - val_acc: 0.0816\n",
            "Epoch 178/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.4456 - acc: 0.3896 - val_loss: 6.1908 - val_acc: 0.0807\n",
            "Epoch 179/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.4417 - acc: 0.3902 - val_loss: 6.2039 - val_acc: 0.0784\n",
            "Epoch 180/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.4372 - acc: 0.3931 - val_loss: 6.2005 - val_acc: 0.0796\n",
            "Epoch 181/1000\n",
            "1148/1148 [==============================] - 0s 338us/step - loss: 1.4323 - acc: 0.3923 - val_loss: 6.2146 - val_acc: 0.0813\n",
            "Epoch 182/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.4269 - acc: 0.3937 - val_loss: 6.2141 - val_acc: 0.0802\n",
            "Epoch 183/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.4234 - acc: 0.3947 - val_loss: 6.2273 - val_acc: 0.0807\n",
            "Epoch 184/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.4209 - acc: 0.3949 - val_loss: 6.2346 - val_acc: 0.0804\n",
            "Epoch 185/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.4159 - acc: 0.3945 - val_loss: 6.2409 - val_acc: 0.0793\n",
            "Epoch 186/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.4127 - acc: 0.3950 - val_loss: 6.2480 - val_acc: 0.0793\n",
            "Epoch 187/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 1.4071 - acc: 0.3977 - val_loss: 6.2527 - val_acc: 0.0790\n",
            "Epoch 188/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.4018 - acc: 0.3978 - val_loss: 6.2566 - val_acc: 0.0796\n",
            "Epoch 189/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.3985 - acc: 0.3971 - val_loss: 6.2671 - val_acc: 0.0784\n",
            "Epoch 190/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.3932 - acc: 0.3991 - val_loss: 6.2677 - val_acc: 0.0796\n",
            "Epoch 191/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.3900 - acc: 0.4008 - val_loss: 6.2746 - val_acc: 0.0787\n",
            "Epoch 192/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.3858 - acc: 0.4022 - val_loss: 6.2839 - val_acc: 0.0790\n",
            "Epoch 193/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.3815 - acc: 0.4020 - val_loss: 6.2894 - val_acc: 0.0778\n",
            "Epoch 194/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.3766 - acc: 0.4029 - val_loss: 6.2982 - val_acc: 0.0793\n",
            "Epoch 195/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.3752 - acc: 0.4025 - val_loss: 6.3013 - val_acc: 0.0773\n",
            "Epoch 196/1000\n",
            "1148/1148 [==============================] - 0s 341us/step - loss: 1.3714 - acc: 0.4042 - val_loss: 6.3029 - val_acc: 0.0802\n",
            "Epoch 197/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 1.3672 - acc: 0.4058 - val_loss: 6.3039 - val_acc: 0.0793\n",
            "Epoch 198/1000\n",
            "1148/1148 [==============================] - 0s 341us/step - loss: 1.3634 - acc: 0.4056 - val_loss: 6.3185 - val_acc: 0.0778\n",
            "Epoch 199/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.3581 - acc: 0.4060 - val_loss: 6.3231 - val_acc: 0.0778\n",
            "Epoch 200/1000\n",
            "1148/1148 [==============================] - 0s 338us/step - loss: 1.3540 - acc: 0.4072 - val_loss: 6.3330 - val_acc: 0.0787\n",
            "Epoch 201/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 1.3506 - acc: 0.4086 - val_loss: 6.3325 - val_acc: 0.0781\n",
            "Epoch 202/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.3449 - acc: 0.4088 - val_loss: 6.3376 - val_acc: 0.0787\n",
            "Epoch 203/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.3417 - acc: 0.4090 - val_loss: 6.3434 - val_acc: 0.0796\n",
            "Epoch 204/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.3371 - acc: 0.4113 - val_loss: 6.3482 - val_acc: 0.0793\n",
            "Epoch 205/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.3325 - acc: 0.4132 - val_loss: 6.3605 - val_acc: 0.0787\n",
            "Epoch 206/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 1.3287 - acc: 0.4127 - val_loss: 6.3606 - val_acc: 0.0767\n",
            "Epoch 207/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.3249 - acc: 0.4136 - val_loss: 6.3733 - val_acc: 0.0767\n",
            "Epoch 208/1000\n",
            "1148/1148 [==============================] - 0s 337us/step - loss: 1.3227 - acc: 0.4138 - val_loss: 6.3800 - val_acc: 0.0767\n",
            "Epoch 209/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.3199 - acc: 0.4127 - val_loss: 6.3839 - val_acc: 0.0764\n",
            "Epoch 210/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.3149 - acc: 0.4159 - val_loss: 6.3883 - val_acc: 0.0773\n",
            "Epoch 211/1000\n",
            "1148/1148 [==============================] - 0s 343us/step - loss: 1.3118 - acc: 0.4163 - val_loss: 6.3909 - val_acc: 0.0784\n",
            "Epoch 212/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 1.3093 - acc: 0.4179 - val_loss: 6.4071 - val_acc: 0.0764\n",
            "Epoch 213/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.3068 - acc: 0.4172 - val_loss: 6.4119 - val_acc: 0.0741\n",
            "Epoch 214/1000\n",
            "1148/1148 [==============================] - 0s 336us/step - loss: 1.3017 - acc: 0.4182 - val_loss: 6.4143 - val_acc: 0.0764\n",
            "Epoch 215/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.2976 - acc: 0.4208 - val_loss: 6.4229 - val_acc: 0.0773\n",
            "Epoch 216/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.2961 - acc: 0.4211 - val_loss: 6.4219 - val_acc: 0.0773\n",
            "Epoch 217/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.2933 - acc: 0.4197 - val_loss: 6.4269 - val_acc: 0.0767\n",
            "Epoch 218/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.2900 - acc: 0.4218 - val_loss: 6.4299 - val_acc: 0.0764\n",
            "Epoch 219/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.2857 - acc: 0.4228 - val_loss: 6.4404 - val_acc: 0.0761\n",
            "Epoch 220/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.2827 - acc: 0.4235 - val_loss: 6.4564 - val_acc: 0.0747\n",
            "Epoch 221/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.2797 - acc: 0.4241 - val_loss: 6.4540 - val_acc: 0.0752\n",
            "Epoch 222/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.2740 - acc: 0.4258 - val_loss: 6.4598 - val_acc: 0.0767\n",
            "Epoch 223/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.2704 - acc: 0.4244 - val_loss: 6.4586 - val_acc: 0.0755\n",
            "Epoch 224/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.2689 - acc: 0.4263 - val_loss: 6.4710 - val_acc: 0.0747\n",
            "Epoch 225/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.2700 - acc: 0.4255 - val_loss: 6.4776 - val_acc: 0.0738\n",
            "Epoch 226/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 1.2649 - acc: 0.4266 - val_loss: 6.4880 - val_acc: 0.0747\n",
            "Epoch 227/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.2619 - acc: 0.4277 - val_loss: 6.4865 - val_acc: 0.0758\n",
            "Epoch 228/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.2588 - acc: 0.4288 - val_loss: 6.4990 - val_acc: 0.0744\n",
            "Epoch 229/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 1.2543 - acc: 0.4296 - val_loss: 6.5012 - val_acc: 0.0735\n",
            "Epoch 230/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.2504 - acc: 0.4289 - val_loss: 6.5048 - val_acc: 0.0738\n",
            "Epoch 231/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 1.2471 - acc: 0.4304 - val_loss: 6.5114 - val_acc: 0.0755\n",
            "Epoch 232/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.2441 - acc: 0.4305 - val_loss: 6.5107 - val_acc: 0.0761\n",
            "Epoch 233/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.2404 - acc: 0.4329 - val_loss: 6.5192 - val_acc: 0.0767\n",
            "Epoch 234/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.2373 - acc: 0.4329 - val_loss: 6.5295 - val_acc: 0.0749\n",
            "Epoch 235/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.2374 - acc: 0.4326 - val_loss: 6.5335 - val_acc: 0.0749\n",
            "Epoch 236/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.2340 - acc: 0.4327 - val_loss: 6.5453 - val_acc: 0.0752\n",
            "Epoch 237/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.2313 - acc: 0.4328 - val_loss: 6.5420 - val_acc: 0.0749\n",
            "Epoch 238/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.2270 - acc: 0.4344 - val_loss: 6.5527 - val_acc: 0.0767\n",
            "Epoch 239/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.2238 - acc: 0.4347 - val_loss: 6.5580 - val_acc: 0.0764\n",
            "Epoch 240/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.2221 - acc: 0.4357 - val_loss: 6.5625 - val_acc: 0.0755\n",
            "Epoch 241/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.2173 - acc: 0.4368 - val_loss: 6.5699 - val_acc: 0.0767\n",
            "Epoch 242/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.2158 - acc: 0.4379 - val_loss: 6.5697 - val_acc: 0.0761\n",
            "Epoch 243/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.2131 - acc: 0.4375 - val_loss: 6.5835 - val_acc: 0.0758\n",
            "Epoch 244/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.2123 - acc: 0.4385 - val_loss: 6.5896 - val_acc: 0.0767\n",
            "Epoch 245/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.2085 - acc: 0.4390 - val_loss: 6.5976 - val_acc: 0.0761\n",
            "Epoch 246/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.2079 - acc: 0.4387 - val_loss: 6.5987 - val_acc: 0.0752\n",
            "Epoch 247/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.2038 - acc: 0.4397 - val_loss: 6.6021 - val_acc: 0.0781\n",
            "Epoch 248/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 1.2021 - acc: 0.4421 - val_loss: 6.6082 - val_acc: 0.0749\n",
            "Epoch 249/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.1981 - acc: 0.4416 - val_loss: 6.6034 - val_acc: 0.0781\n",
            "Epoch 250/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.1968 - acc: 0.4416 - val_loss: 6.6180 - val_acc: 0.0764\n",
            "Epoch 251/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 1.1930 - acc: 0.4437 - val_loss: 6.6242 - val_acc: 0.0784\n",
            "Epoch 252/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.1920 - acc: 0.4423 - val_loss: 6.6293 - val_acc: 0.0747\n",
            "Epoch 253/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.1926 - acc: 0.4424 - val_loss: 6.6328 - val_acc: 0.0752\n",
            "Epoch 254/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.1950 - acc: 0.4406 - val_loss: 6.6395 - val_acc: 0.0755\n",
            "Epoch 255/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.1908 - acc: 0.4434 - val_loss: 6.6318 - val_acc: 0.0758\n",
            "Epoch 256/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.1857 - acc: 0.4448 - val_loss: 6.6427 - val_acc: 0.0747\n",
            "Epoch 257/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 1.1829 - acc: 0.4448 - val_loss: 6.6473 - val_acc: 0.0747\n",
            "Epoch 258/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.1792 - acc: 0.4458 - val_loss: 6.6597 - val_acc: 0.0752\n",
            "Epoch 259/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.1780 - acc: 0.4458 - val_loss: 6.6523 - val_acc: 0.0787\n",
            "Epoch 260/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.1733 - acc: 0.4465 - val_loss: 6.6592 - val_acc: 0.0775\n",
            "Epoch 261/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.1685 - acc: 0.4489 - val_loss: 6.6595 - val_acc: 0.0773\n",
            "Epoch 262/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.1659 - acc: 0.4495 - val_loss: 6.6744 - val_acc: 0.0761\n",
            "Epoch 263/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.1622 - acc: 0.4504 - val_loss: 6.6702 - val_acc: 0.0761\n",
            "Epoch 264/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.1596 - acc: 0.4519 - val_loss: 6.6792 - val_acc: 0.0755\n",
            "Epoch 265/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 1.1557 - acc: 0.4515 - val_loss: 6.6809 - val_acc: 0.0761\n",
            "Epoch 266/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.1543 - acc: 0.4517 - val_loss: 6.6944 - val_acc: 0.0775\n",
            "Epoch 267/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.1521 - acc: 0.4535 - val_loss: 6.6969 - val_acc: 0.0752\n",
            "Epoch 268/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.1529 - acc: 0.4520 - val_loss: 6.7096 - val_acc: 0.0775\n",
            "Epoch 269/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.1507 - acc: 0.4513 - val_loss: 6.7089 - val_acc: 0.0773\n",
            "Epoch 270/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.1475 - acc: 0.4533 - val_loss: 6.7232 - val_acc: 0.0752\n",
            "Epoch 271/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.1438 - acc: 0.4530 - val_loss: 6.7189 - val_acc: 0.0749\n",
            "Epoch 272/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.1418 - acc: 0.4535 - val_loss: 6.7305 - val_acc: 0.0758\n",
            "Epoch 273/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.1392 - acc: 0.4546 - val_loss: 6.7333 - val_acc: 0.0755\n",
            "Epoch 274/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.1368 - acc: 0.4549 - val_loss: 6.7383 - val_acc: 0.0758\n",
            "Epoch 275/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.1336 - acc: 0.4572 - val_loss: 6.7314 - val_acc: 0.0767\n",
            "Epoch 276/1000\n",
            "1148/1148 [==============================] - 0s 335us/step - loss: 1.1309 - acc: 0.4575 - val_loss: 6.7392 - val_acc: 0.0747\n",
            "Epoch 277/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.1272 - acc: 0.4585 - val_loss: 6.7464 - val_acc: 0.0755\n",
            "Epoch 278/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.1252 - acc: 0.4601 - val_loss: 6.7515 - val_acc: 0.0752\n",
            "Epoch 279/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 1.1228 - acc: 0.4601 - val_loss: 6.7600 - val_acc: 0.0755\n",
            "Epoch 280/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.1214 - acc: 0.4609 - val_loss: 6.7614 - val_acc: 0.0749\n",
            "Epoch 281/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 1.1183 - acc: 0.4588 - val_loss: 6.7636 - val_acc: 0.0749\n",
            "Epoch 282/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.1182 - acc: 0.4615 - val_loss: 6.7697 - val_acc: 0.0735\n",
            "Epoch 283/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 1.1164 - acc: 0.4615 - val_loss: 6.7754 - val_acc: 0.0761\n",
            "Epoch 284/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 1.1134 - acc: 0.4621 - val_loss: 6.7711 - val_acc: 0.0752\n",
            "Epoch 285/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.1146 - acc: 0.4623 - val_loss: 6.7878 - val_acc: 0.0744\n",
            "Epoch 286/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.1142 - acc: 0.4623 - val_loss: 6.7843 - val_acc: 0.0747\n",
            "Epoch 287/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.1121 - acc: 0.4623 - val_loss: 6.7842 - val_acc: 0.0749\n",
            "Epoch 288/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.1090 - acc: 0.4624 - val_loss: 6.7925 - val_acc: 0.0755\n",
            "Epoch 289/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.1076 - acc: 0.4621 - val_loss: 6.7917 - val_acc: 0.0749\n",
            "Epoch 290/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 1.1053 - acc: 0.4619 - val_loss: 6.7954 - val_acc: 0.0735\n",
            "Epoch 291/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.1067 - acc: 0.4627 - val_loss: 6.7967 - val_acc: 0.0738\n",
            "Epoch 292/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.1052 - acc: 0.4632 - val_loss: 6.8038 - val_acc: 0.0744\n",
            "Epoch 293/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.1031 - acc: 0.4629 - val_loss: 6.8041 - val_acc: 0.0758\n",
            "Epoch 294/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.1013 - acc: 0.4641 - val_loss: 6.8206 - val_acc: 0.0749\n",
            "Epoch 295/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.0957 - acc: 0.4653 - val_loss: 6.8172 - val_acc: 0.0735\n",
            "Epoch 296/1000\n",
            "1148/1148 [==============================] - 0s 340us/step - loss: 1.0927 - acc: 0.4650 - val_loss: 6.8354 - val_acc: 0.0735\n",
            "Epoch 297/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 1.0909 - acc: 0.4654 - val_loss: 6.8263 - val_acc: 0.0738\n",
            "Epoch 298/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.0886 - acc: 0.4646 - val_loss: 6.8457 - val_acc: 0.0744\n",
            "Epoch 299/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 1.0889 - acc: 0.4670 - val_loss: 6.8337 - val_acc: 0.0741\n",
            "Epoch 300/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.0847 - acc: 0.4685 - val_loss: 6.8349 - val_acc: 0.0744\n",
            "Epoch 301/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0812 - acc: 0.4684 - val_loss: 6.8410 - val_acc: 0.0752\n",
            "Epoch 302/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.0800 - acc: 0.4691 - val_loss: 6.8433 - val_acc: 0.0741\n",
            "Epoch 303/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.0781 - acc: 0.4690 - val_loss: 6.8526 - val_acc: 0.0738\n",
            "Epoch 304/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0749 - acc: 0.4688 - val_loss: 6.8534 - val_acc: 0.0732\n",
            "Epoch 305/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.0727 - acc: 0.4708 - val_loss: 6.8655 - val_acc: 0.0723\n",
            "Epoch 306/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.0740 - acc: 0.4697 - val_loss: 6.8638 - val_acc: 0.0726\n",
            "Epoch 307/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 1.0736 - acc: 0.4702 - val_loss: 6.8742 - val_acc: 0.0723\n",
            "Epoch 308/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.0738 - acc: 0.4688 - val_loss: 6.8726 - val_acc: 0.0752\n",
            "Epoch 309/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 1.0736 - acc: 0.4702 - val_loss: 6.8803 - val_acc: 0.0732\n",
            "Epoch 310/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.0721 - acc: 0.4707 - val_loss: 6.8719 - val_acc: 0.0741\n",
            "Epoch 311/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 1.0699 - acc: 0.4700 - val_loss: 6.8900 - val_acc: 0.0723\n",
            "Epoch 312/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.0686 - acc: 0.4726 - val_loss: 6.8868 - val_acc: 0.0744\n",
            "Epoch 313/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.0658 - acc: 0.4707 - val_loss: 6.8915 - val_acc: 0.0752\n",
            "Epoch 314/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.0649 - acc: 0.4722 - val_loss: 6.9009 - val_acc: 0.0744\n",
            "Epoch 315/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.0627 - acc: 0.4715 - val_loss: 6.9078 - val_acc: 0.0723\n",
            "Epoch 316/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.0601 - acc: 0.4731 - val_loss: 6.9101 - val_acc: 0.0735\n",
            "Epoch 317/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0561 - acc: 0.4758 - val_loss: 6.9039 - val_acc: 0.0749\n",
            "Epoch 318/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 1.0524 - acc: 0.4752 - val_loss: 6.9133 - val_acc: 0.0732\n",
            "Epoch 319/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.0527 - acc: 0.4756 - val_loss: 6.9140 - val_acc: 0.0755\n",
            "Epoch 320/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 1.0534 - acc: 0.4742 - val_loss: 6.9075 - val_acc: 0.0726\n",
            "Epoch 321/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 1.0506 - acc: 0.4744 - val_loss: 6.9215 - val_acc: 0.0749\n",
            "Epoch 322/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.0479 - acc: 0.4752 - val_loss: 6.9325 - val_acc: 0.0712\n",
            "Epoch 323/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.0445 - acc: 0.4776 - val_loss: 6.9330 - val_acc: 0.0752\n",
            "Epoch 324/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 1.0434 - acc: 0.4776 - val_loss: 6.9262 - val_acc: 0.0741\n",
            "Epoch 325/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 1.0422 - acc: 0.4776 - val_loss: 6.9321 - val_acc: 0.0758\n",
            "Epoch 326/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.0407 - acc: 0.4763 - val_loss: 6.9493 - val_acc: 0.0752\n",
            "Epoch 327/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0383 - acc: 0.4784 - val_loss: 6.9453 - val_acc: 0.0735\n",
            "Epoch 328/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 1.0365 - acc: 0.4779 - val_loss: 6.9452 - val_acc: 0.0747\n",
            "Epoch 329/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.0336 - acc: 0.4786 - val_loss: 6.9497 - val_acc: 0.0744\n",
            "Epoch 330/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 1.0306 - acc: 0.4805 - val_loss: 6.9570 - val_acc: 0.0729\n",
            "Epoch 331/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 1.0285 - acc: 0.4811 - val_loss: 6.9557 - val_acc: 0.0732\n",
            "Epoch 332/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.0263 - acc: 0.4805 - val_loss: 6.9635 - val_acc: 0.0752\n",
            "Epoch 333/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.0250 - acc: 0.4823 - val_loss: 6.9625 - val_acc: 0.0747\n",
            "Epoch 334/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0247 - acc: 0.4800 - val_loss: 6.9754 - val_acc: 0.0735\n",
            "Epoch 335/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.0234 - acc: 0.4815 - val_loss: 6.9676 - val_acc: 0.0732\n",
            "Epoch 336/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 1.0220 - acc: 0.4821 - val_loss: 6.9799 - val_acc: 0.0744\n",
            "Epoch 337/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.0197 - acc: 0.4828 - val_loss: 6.9818 - val_acc: 0.0744\n",
            "Epoch 338/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 1.0178 - acc: 0.4825 - val_loss: 6.9894 - val_acc: 0.0738\n",
            "Epoch 339/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 1.0176 - acc: 0.4833 - val_loss: 6.9932 - val_acc: 0.0738\n",
            "Epoch 340/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.0167 - acc: 0.4844 - val_loss: 6.9932 - val_acc: 0.0738\n",
            "Epoch 341/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0148 - acc: 0.4835 - val_loss: 6.9993 - val_acc: 0.0729\n",
            "Epoch 342/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 1.0123 - acc: 0.4840 - val_loss: 6.9977 - val_acc: 0.0741\n",
            "Epoch 343/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 1.0156 - acc: 0.4825 - val_loss: 7.0034 - val_acc: 0.0718\n",
            "Epoch 344/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 1.0219 - acc: 0.4805 - val_loss: 7.0292 - val_acc: 0.0741\n",
            "Epoch 345/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 1.0215 - acc: 0.4799 - val_loss: 7.0085 - val_acc: 0.0738\n",
            "Epoch 346/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.0170 - acc: 0.4819 - val_loss: 7.0249 - val_acc: 0.0741\n",
            "Epoch 347/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0160 - acc: 0.4819 - val_loss: 7.0274 - val_acc: 0.0735\n",
            "Epoch 348/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 1.0120 - acc: 0.4832 - val_loss: 7.0241 - val_acc: 0.0741\n",
            "Epoch 349/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 1.0081 - acc: 0.4810 - val_loss: 7.0426 - val_acc: 0.0720\n",
            "Epoch 350/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 1.0066 - acc: 0.4834 - val_loss: 7.0342 - val_acc: 0.0726\n",
            "Epoch 351/1000\n",
            "1148/1148 [==============================] - 0s 305us/step - loss: 1.0032 - acc: 0.4845 - val_loss: 7.0409 - val_acc: 0.0718\n",
            "Epoch 352/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 1.0001 - acc: 0.4864 - val_loss: 7.0441 - val_acc: 0.0732\n",
            "Epoch 353/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.9978 - acc: 0.4870 - val_loss: 7.0458 - val_acc: 0.0718\n",
            "Epoch 354/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.9955 - acc: 0.4863 - val_loss: 7.0546 - val_acc: 0.0729\n",
            "Epoch 355/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.9949 - acc: 0.4869 - val_loss: 7.0551 - val_acc: 0.0720\n",
            "Epoch 356/1000\n",
            "1148/1148 [==============================] - 0s 335us/step - loss: 0.9911 - acc: 0.4871 - val_loss: 7.0584 - val_acc: 0.0718\n",
            "Epoch 357/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.9911 - acc: 0.4872 - val_loss: 7.0634 - val_acc: 0.0718\n",
            "Epoch 358/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9900 - acc: 0.4897 - val_loss: 7.0609 - val_acc: 0.0712\n",
            "Epoch 359/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.9879 - acc: 0.4897 - val_loss: 7.0632 - val_acc: 0.0712\n",
            "Epoch 360/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9851 - acc: 0.4890 - val_loss: 7.0776 - val_acc: 0.0720\n",
            "Epoch 361/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9848 - acc: 0.4898 - val_loss: 7.0689 - val_acc: 0.0718\n",
            "Epoch 362/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.9845 - acc: 0.4912 - val_loss: 7.0756 - val_acc: 0.0726\n",
            "Epoch 363/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.9821 - acc: 0.4904 - val_loss: 7.0821 - val_acc: 0.0726\n",
            "Epoch 364/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.9787 - acc: 0.4905 - val_loss: 7.0809 - val_acc: 0.0738\n",
            "Epoch 365/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9780 - acc: 0.4905 - val_loss: 7.0831 - val_acc: 0.0735\n",
            "Epoch 366/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9761 - acc: 0.4915 - val_loss: 7.0943 - val_acc: 0.0726\n",
            "Epoch 367/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.9764 - acc: 0.4899 - val_loss: 7.0911 - val_acc: 0.0718\n",
            "Epoch 368/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.9725 - acc: 0.4925 - val_loss: 7.1048 - val_acc: 0.0712\n",
            "Epoch 369/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.9708 - acc: 0.4930 - val_loss: 7.1103 - val_acc: 0.0723\n",
            "Epoch 370/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9707 - acc: 0.4947 - val_loss: 7.1181 - val_acc: 0.0706\n",
            "Epoch 371/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9708 - acc: 0.4941 - val_loss: 7.1046 - val_acc: 0.0735\n",
            "Epoch 372/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9689 - acc: 0.4938 - val_loss: 7.1199 - val_acc: 0.0715\n",
            "Epoch 373/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9680 - acc: 0.4935 - val_loss: 7.1154 - val_acc: 0.0706\n",
            "Epoch 374/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.9677 - acc: 0.4940 - val_loss: 7.1286 - val_acc: 0.0726\n",
            "Epoch 375/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9690 - acc: 0.4930 - val_loss: 7.1365 - val_acc: 0.0720\n",
            "Epoch 376/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.9695 - acc: 0.4924 - val_loss: 7.1369 - val_acc: 0.0715\n",
            "Epoch 377/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9727 - acc: 0.4911 - val_loss: 7.1491 - val_acc: 0.0709\n",
            "Epoch 378/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9705 - acc: 0.4907 - val_loss: 7.1502 - val_acc: 0.0715\n",
            "Epoch 379/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9698 - acc: 0.4925 - val_loss: 7.1476 - val_acc: 0.0720\n",
            "Epoch 380/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9654 - acc: 0.4930 - val_loss: 7.1492 - val_acc: 0.0729\n",
            "Epoch 381/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.9609 - acc: 0.4938 - val_loss: 7.1501 - val_acc: 0.0723\n",
            "Epoch 382/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.9589 - acc: 0.4951 - val_loss: 7.1494 - val_acc: 0.0735\n",
            "Epoch 383/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.9557 - acc: 0.4966 - val_loss: 7.1561 - val_acc: 0.0718\n",
            "Epoch 384/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.9544 - acc: 0.4931 - val_loss: 7.1651 - val_acc: 0.0723\n",
            "Epoch 385/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9520 - acc: 0.4985 - val_loss: 7.1719 - val_acc: 0.0720\n",
            "Epoch 386/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.9552 - acc: 0.4961 - val_loss: 7.1802 - val_acc: 0.0741\n",
            "Epoch 387/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9554 - acc: 0.4967 - val_loss: 7.1784 - val_acc: 0.0694\n",
            "Epoch 388/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9575 - acc: 0.4940 - val_loss: 7.1830 - val_acc: 0.0735\n",
            "Epoch 389/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.9530 - acc: 0.4972 - val_loss: 7.1819 - val_acc: 0.0715\n",
            "Epoch 390/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9531 - acc: 0.4964 - val_loss: 7.1988 - val_acc: 0.0703\n",
            "Epoch 391/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9506 - acc: 0.4986 - val_loss: 7.1914 - val_acc: 0.0700\n",
            "Epoch 392/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9506 - acc: 0.4972 - val_loss: 7.1955 - val_acc: 0.0715\n",
            "Epoch 393/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9499 - acc: 0.4984 - val_loss: 7.1977 - val_acc: 0.0706\n",
            "Epoch 394/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9475 - acc: 0.4999 - val_loss: 7.1956 - val_acc: 0.0723\n",
            "Epoch 395/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.9440 - acc: 0.4993 - val_loss: 7.1963 - val_acc: 0.0720\n",
            "Epoch 396/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9422 - acc: 0.5001 - val_loss: 7.2068 - val_acc: 0.0729\n",
            "Epoch 397/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9409 - acc: 0.4996 - val_loss: 7.2128 - val_acc: 0.0729\n",
            "Epoch 398/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9392 - acc: 0.5004 - val_loss: 7.2167 - val_acc: 0.0703\n",
            "Epoch 399/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9391 - acc: 0.5016 - val_loss: 7.2117 - val_acc: 0.0729\n",
            "Epoch 400/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9381 - acc: 0.5010 - val_loss: 7.2256 - val_acc: 0.0718\n",
            "Epoch 401/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9360 - acc: 0.5019 - val_loss: 7.2279 - val_acc: 0.0718\n",
            "Epoch 402/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9338 - acc: 0.5017 - val_loss: 7.2347 - val_acc: 0.0720\n",
            "Epoch 403/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9336 - acc: 0.4998 - val_loss: 7.2276 - val_acc: 0.0732\n",
            "Epoch 404/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9314 - acc: 0.5031 - val_loss: 7.2343 - val_acc: 0.0720\n",
            "Epoch 405/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9299 - acc: 0.5019 - val_loss: 7.2311 - val_acc: 0.0726\n",
            "Epoch 406/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.9276 - acc: 0.5030 - val_loss: 7.2384 - val_acc: 0.0729\n",
            "Epoch 407/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9274 - acc: 0.5033 - val_loss: 7.2367 - val_acc: 0.0715\n",
            "Epoch 408/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9254 - acc: 0.5041 - val_loss: 7.2346 - val_acc: 0.0720\n",
            "Epoch 409/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.9258 - acc: 0.5038 - val_loss: 7.2438 - val_acc: 0.0723\n",
            "Epoch 410/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9243 - acc: 0.5038 - val_loss: 7.2397 - val_acc: 0.0720\n",
            "Epoch 411/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.9235 - acc: 0.5031 - val_loss: 7.2472 - val_acc: 0.0715\n",
            "Epoch 412/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.9234 - acc: 0.5027 - val_loss: 7.2528 - val_acc: 0.0720\n",
            "Epoch 413/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9230 - acc: 0.5040 - val_loss: 7.2564 - val_acc: 0.0723\n",
            "Epoch 414/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9225 - acc: 0.5043 - val_loss: 7.2635 - val_acc: 0.0709\n",
            "Epoch 415/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9205 - acc: 0.5044 - val_loss: 7.2617 - val_acc: 0.0726\n",
            "Epoch 416/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9175 - acc: 0.5055 - val_loss: 7.2638 - val_acc: 0.0720\n",
            "Epoch 417/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.9161 - acc: 0.5068 - val_loss: 7.2679 - val_acc: 0.0712\n",
            "Epoch 418/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.9149 - acc: 0.5077 - val_loss: 7.2725 - val_acc: 0.0715\n",
            "Epoch 419/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9164 - acc: 0.5047 - val_loss: 7.2723 - val_acc: 0.0726\n",
            "Epoch 420/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9146 - acc: 0.5054 - val_loss: 7.2723 - val_acc: 0.0732\n",
            "Epoch 421/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9147 - acc: 0.5054 - val_loss: 7.2740 - val_acc: 0.0723\n",
            "Epoch 422/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.9134 - acc: 0.5055 - val_loss: 7.2813 - val_acc: 0.0709\n",
            "Epoch 423/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.9115 - acc: 0.5060 - val_loss: 7.2849 - val_acc: 0.0709\n",
            "Epoch 424/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.9117 - acc: 0.5068 - val_loss: 7.2893 - val_acc: 0.0718\n",
            "Epoch 425/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.9101 - acc: 0.5068 - val_loss: 7.2902 - val_acc: 0.0712\n",
            "Epoch 426/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9084 - acc: 0.5062 - val_loss: 7.2947 - val_acc: 0.0718\n",
            "Epoch 427/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.9080 - acc: 0.5067 - val_loss: 7.3035 - val_acc: 0.0715\n",
            "Epoch 428/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9062 - acc: 0.5091 - val_loss: 7.2994 - val_acc: 0.0715\n",
            "Epoch 429/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.9061 - acc: 0.5075 - val_loss: 7.3054 - val_acc: 0.0703\n",
            "Epoch 430/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.9053 - acc: 0.5092 - val_loss: 7.3187 - val_acc: 0.0715\n",
            "Epoch 431/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.9047 - acc: 0.5073 - val_loss: 7.3131 - val_acc: 0.0706\n",
            "Epoch 432/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.9036 - acc: 0.5070 - val_loss: 7.3222 - val_acc: 0.0689\n",
            "Epoch 433/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9027 - acc: 0.5088 - val_loss: 7.3071 - val_acc: 0.0712\n",
            "Epoch 434/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9035 - acc: 0.5086 - val_loss: 7.3268 - val_acc: 0.0703\n",
            "Epoch 435/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9000 - acc: 0.5086 - val_loss: 7.3177 - val_acc: 0.0697\n",
            "Epoch 436/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8999 - acc: 0.5103 - val_loss: 7.3270 - val_acc: 0.0726\n",
            "Epoch 437/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.8995 - acc: 0.5094 - val_loss: 7.3185 - val_acc: 0.0723\n",
            "Epoch 438/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.9016 - acc: 0.5065 - val_loss: 7.3219 - val_acc: 0.0712\n",
            "Epoch 439/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.9030 - acc: 0.5066 - val_loss: 7.3214 - val_acc: 0.0706\n",
            "Epoch 440/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9023 - acc: 0.5084 - val_loss: 7.3265 - val_acc: 0.0718\n",
            "Epoch 441/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 0.9013 - acc: 0.5075 - val_loss: 7.3315 - val_acc: 0.0720\n",
            "Epoch 442/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.8989 - acc: 0.5073 - val_loss: 7.3365 - val_acc: 0.0715\n",
            "Epoch 443/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8981 - acc: 0.5080 - val_loss: 7.3402 - val_acc: 0.0709\n",
            "Epoch 444/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8986 - acc: 0.5081 - val_loss: 7.3529 - val_acc: 0.0689\n",
            "Epoch 445/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9068 - acc: 0.5061 - val_loss: 7.3387 - val_acc: 0.0712\n",
            "Epoch 446/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.9072 - acc: 0.5060 - val_loss: 7.3497 - val_acc: 0.0726\n",
            "Epoch 447/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.9067 - acc: 0.5053 - val_loss: 7.3491 - val_acc: 0.0709\n",
            "Epoch 448/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.9043 - acc: 0.5068 - val_loss: 7.3383 - val_acc: 0.0709\n",
            "Epoch 449/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.9040 - acc: 0.5057 - val_loss: 7.3441 - val_acc: 0.0723\n",
            "Epoch 450/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.9017 - acc: 0.5059 - val_loss: 7.3527 - val_acc: 0.0694\n",
            "Epoch 451/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8989 - acc: 0.5082 - val_loss: 7.3610 - val_acc: 0.0709\n",
            "Epoch 452/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8969 - acc: 0.5096 - val_loss: 7.3653 - val_acc: 0.0712\n",
            "Epoch 453/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8941 - acc: 0.5094 - val_loss: 7.3446 - val_acc: 0.0718\n",
            "Epoch 454/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8908 - acc: 0.5105 - val_loss: 7.3544 - val_acc: 0.0720\n",
            "Epoch 455/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8883 - acc: 0.5110 - val_loss: 7.3583 - val_acc: 0.0694\n",
            "Epoch 456/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8848 - acc: 0.5110 - val_loss: 7.3456 - val_acc: 0.0720\n",
            "Epoch 457/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8822 - acc: 0.5133 - val_loss: 7.3648 - val_acc: 0.0700\n",
            "Epoch 458/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.8803 - acc: 0.5146 - val_loss: 7.3591 - val_acc: 0.0712\n",
            "Epoch 459/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.8793 - acc: 0.5127 - val_loss: 7.3706 - val_acc: 0.0694\n",
            "Epoch 460/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8788 - acc: 0.5136 - val_loss: 7.3714 - val_acc: 0.0694\n",
            "Epoch 461/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8782 - acc: 0.5144 - val_loss: 7.3708 - val_acc: 0.0718\n",
            "Epoch 462/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8750 - acc: 0.5147 - val_loss: 7.3836 - val_acc: 0.0712\n",
            "Epoch 463/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8747 - acc: 0.5135 - val_loss: 7.3829 - val_acc: 0.0706\n",
            "Epoch 464/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8735 - acc: 0.5146 - val_loss: 7.3913 - val_acc: 0.0718\n",
            "Epoch 465/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8757 - acc: 0.5143 - val_loss: 7.3873 - val_acc: 0.0703\n",
            "Epoch 466/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8727 - acc: 0.5144 - val_loss: 7.3901 - val_acc: 0.0697\n",
            "Epoch 467/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.8719 - acc: 0.5150 - val_loss: 7.3950 - val_acc: 0.0700\n",
            "Epoch 468/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.8755 - acc: 0.5143 - val_loss: 7.4024 - val_acc: 0.0718\n",
            "Epoch 469/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 0.8741 - acc: 0.5128 - val_loss: 7.4131 - val_acc: 0.0689\n",
            "Epoch 470/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.8757 - acc: 0.5122 - val_loss: 7.4084 - val_acc: 0.0692\n",
            "Epoch 471/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.8750 - acc: 0.5144 - val_loss: 7.4032 - val_acc: 0.0692\n",
            "Epoch 472/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8744 - acc: 0.5144 - val_loss: 7.4077 - val_acc: 0.0700\n",
            "Epoch 473/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8729 - acc: 0.5134 - val_loss: 7.4311 - val_acc: 0.0668\n",
            "Epoch 474/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8720 - acc: 0.5146 - val_loss: 7.4169 - val_acc: 0.0689\n",
            "Epoch 475/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8704 - acc: 0.5154 - val_loss: 7.4309 - val_acc: 0.0689\n",
            "Epoch 476/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8689 - acc: 0.5151 - val_loss: 7.4261 - val_acc: 0.0703\n",
            "Epoch 477/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8710 - acc: 0.5144 - val_loss: 7.4381 - val_acc: 0.0689\n",
            "Epoch 478/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8712 - acc: 0.5141 - val_loss: 7.4316 - val_acc: 0.0680\n",
            "Epoch 479/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8719 - acc: 0.5142 - val_loss: 7.4411 - val_acc: 0.0694\n",
            "Epoch 480/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.8705 - acc: 0.5158 - val_loss: 7.4476 - val_acc: 0.0697\n",
            "Epoch 481/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 0.8686 - acc: 0.5151 - val_loss: 7.4345 - val_acc: 0.0686\n",
            "Epoch 482/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8679 - acc: 0.5155 - val_loss: 7.4397 - val_acc: 0.0683\n",
            "Epoch 483/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8680 - acc: 0.5166 - val_loss: 7.4349 - val_acc: 0.0686\n",
            "Epoch 484/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8678 - acc: 0.5149 - val_loss: 7.4295 - val_acc: 0.0686\n",
            "Epoch 485/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8647 - acc: 0.5163 - val_loss: 7.4487 - val_acc: 0.0694\n",
            "Epoch 486/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8629 - acc: 0.5171 - val_loss: 7.4429 - val_acc: 0.0694\n",
            "Epoch 487/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8614 - acc: 0.5169 - val_loss: 7.4510 - val_acc: 0.0697\n",
            "Epoch 488/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8597 - acc: 0.5180 - val_loss: 7.4541 - val_acc: 0.0683\n",
            "Epoch 489/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8608 - acc: 0.5170 - val_loss: 7.4491 - val_acc: 0.0677\n",
            "Epoch 490/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8608 - acc: 0.5176 - val_loss: 7.4580 - val_acc: 0.0668\n",
            "Epoch 491/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.8596 - acc: 0.5176 - val_loss: 7.4581 - val_acc: 0.0686\n",
            "Epoch 492/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8600 - acc: 0.5179 - val_loss: 7.4696 - val_acc: 0.0697\n",
            "Epoch 493/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8589 - acc: 0.5176 - val_loss: 7.4665 - val_acc: 0.0700\n",
            "Epoch 494/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8624 - acc: 0.5155 - val_loss: 7.4660 - val_acc: 0.0715\n",
            "Epoch 495/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8654 - acc: 0.5158 - val_loss: 7.4613 - val_acc: 0.0712\n",
            "Epoch 496/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8640 - acc: 0.5148 - val_loss: 7.4725 - val_acc: 0.0703\n",
            "Epoch 497/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8617 - acc: 0.5155 - val_loss: 7.4654 - val_acc: 0.0703\n",
            "Epoch 498/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8580 - acc: 0.5171 - val_loss: 7.4736 - val_acc: 0.0715\n",
            "Epoch 499/1000\n",
            "1148/1148 [==============================] - 0s 333us/step - loss: 0.8548 - acc: 0.5184 - val_loss: 7.4879 - val_acc: 0.0709\n",
            "Epoch 500/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8538 - acc: 0.5189 - val_loss: 7.4806 - val_acc: 0.0700\n",
            "Epoch 501/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8534 - acc: 0.5184 - val_loss: 7.4863 - val_acc: 0.0697\n",
            "Epoch 502/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.8531 - acc: 0.5182 - val_loss: 7.4910 - val_acc: 0.0700\n",
            "Epoch 503/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8540 - acc: 0.5186 - val_loss: 7.4965 - val_acc: 0.0703\n",
            "Epoch 504/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8512 - acc: 0.5193 - val_loss: 7.5003 - val_acc: 0.0700\n",
            "Epoch 505/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8500 - acc: 0.5191 - val_loss: 7.4969 - val_acc: 0.0700\n",
            "Epoch 506/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8498 - acc: 0.5188 - val_loss: 7.4956 - val_acc: 0.0700\n",
            "Epoch 507/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8471 - acc: 0.5200 - val_loss: 7.4993 - val_acc: 0.0706\n",
            "Epoch 508/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8464 - acc: 0.5200 - val_loss: 7.5017 - val_acc: 0.0680\n",
            "Epoch 509/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8458 - acc: 0.5202 - val_loss: 7.5094 - val_acc: 0.0712\n",
            "Epoch 510/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8425 - acc: 0.5219 - val_loss: 7.5101 - val_acc: 0.0706\n",
            "Epoch 511/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.8407 - acc: 0.5210 - val_loss: 7.5244 - val_acc: 0.0694\n",
            "Epoch 512/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8411 - acc: 0.5214 - val_loss: 7.5164 - val_acc: 0.0709\n",
            "Epoch 513/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8386 - acc: 0.5221 - val_loss: 7.5224 - val_acc: 0.0703\n",
            "Epoch 514/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8378 - acc: 0.5224 - val_loss: 7.5236 - val_acc: 0.0709\n",
            "Epoch 515/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8397 - acc: 0.5207 - val_loss: 7.5180 - val_acc: 0.0686\n",
            "Epoch 516/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.8381 - acc: 0.5216 - val_loss: 7.5209 - val_acc: 0.0709\n",
            "Epoch 517/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8407 - acc: 0.5224 - val_loss: 7.5265 - val_acc: 0.0709\n",
            "Epoch 518/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8378 - acc: 0.5229 - val_loss: 7.5154 - val_acc: 0.0706\n",
            "Epoch 519/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.8371 - acc: 0.5224 - val_loss: 7.5276 - val_acc: 0.0692\n",
            "Epoch 520/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.8365 - acc: 0.5209 - val_loss: 7.5297 - val_acc: 0.0703\n",
            "Epoch 521/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.8352 - acc: 0.5226 - val_loss: 7.5237 - val_acc: 0.0718\n",
            "Epoch 522/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8358 - acc: 0.5215 - val_loss: 7.5368 - val_acc: 0.0697\n",
            "Epoch 523/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8382 - acc: 0.5201 - val_loss: 7.5424 - val_acc: 0.0692\n",
            "Epoch 524/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8397 - acc: 0.5201 - val_loss: 7.5320 - val_acc: 0.0694\n",
            "Epoch 525/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.8390 - acc: 0.5218 - val_loss: 7.5290 - val_acc: 0.0709\n",
            "Epoch 526/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8356 - acc: 0.5220 - val_loss: 7.5382 - val_acc: 0.0689\n",
            "Epoch 527/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8387 - acc: 0.5209 - val_loss: 7.5355 - val_acc: 0.0686\n",
            "Epoch 528/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8370 - acc: 0.5216 - val_loss: 7.5353 - val_acc: 0.0694\n",
            "Epoch 529/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8370 - acc: 0.5207 - val_loss: 7.5358 - val_acc: 0.0686\n",
            "Epoch 530/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8397 - acc: 0.5205 - val_loss: 7.5362 - val_acc: 0.0703\n",
            "Epoch 531/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8389 - acc: 0.5211 - val_loss: 7.5386 - val_acc: 0.0709\n",
            "Epoch 532/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8378 - acc: 0.5208 - val_loss: 7.5356 - val_acc: 0.0683\n",
            "Epoch 533/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8342 - acc: 0.5224 - val_loss: 7.5391 - val_acc: 0.0697\n",
            "Epoch 534/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8365 - acc: 0.5211 - val_loss: 7.5497 - val_acc: 0.0697\n",
            "Epoch 535/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8381 - acc: 0.5208 - val_loss: 7.5414 - val_acc: 0.0709\n",
            "Epoch 536/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8348 - acc: 0.5211 - val_loss: 7.5504 - val_acc: 0.0703\n",
            "Epoch 537/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8342 - acc: 0.5205 - val_loss: 7.5487 - val_acc: 0.0709\n",
            "Epoch 538/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.8328 - acc: 0.5218 - val_loss: 7.5546 - val_acc: 0.0726\n",
            "Epoch 539/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8300 - acc: 0.5223 - val_loss: 7.5696 - val_acc: 0.0706\n",
            "Epoch 540/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8270 - acc: 0.5233 - val_loss: 7.5661 - val_acc: 0.0709\n",
            "Epoch 541/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8271 - acc: 0.5236 - val_loss: 7.5676 - val_acc: 0.0715\n",
            "Epoch 542/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8246 - acc: 0.5246 - val_loss: 7.5674 - val_acc: 0.0677\n",
            "Epoch 543/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8233 - acc: 0.5258 - val_loss: 7.5690 - val_acc: 0.0677\n",
            "Epoch 544/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8222 - acc: 0.5255 - val_loss: 7.5726 - val_acc: 0.0694\n",
            "Epoch 545/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8230 - acc: 0.5248 - val_loss: 7.5815 - val_acc: 0.0709\n",
            "Epoch 546/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8230 - acc: 0.5249 - val_loss: 7.5728 - val_acc: 0.0703\n",
            "Epoch 547/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8202 - acc: 0.5255 - val_loss: 7.5766 - val_acc: 0.0692\n",
            "Epoch 548/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8216 - acc: 0.5256 - val_loss: 7.5785 - val_acc: 0.0700\n",
            "Epoch 549/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8185 - acc: 0.5250 - val_loss: 7.5835 - val_acc: 0.0706\n",
            "Epoch 550/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8174 - acc: 0.5255 - val_loss: 7.5840 - val_acc: 0.0689\n",
            "Epoch 551/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8175 - acc: 0.5251 - val_loss: 7.5920 - val_acc: 0.0694\n",
            "Epoch 552/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8179 - acc: 0.5253 - val_loss: 7.5919 - val_acc: 0.0703\n",
            "Epoch 553/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.8191 - acc: 0.5237 - val_loss: 7.5972 - val_acc: 0.0703\n",
            "Epoch 554/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8177 - acc: 0.5251 - val_loss: 7.5967 - val_acc: 0.0692\n",
            "Epoch 555/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8149 - acc: 0.5279 - val_loss: 7.6046 - val_acc: 0.0689\n",
            "Epoch 556/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.8142 - acc: 0.5264 - val_loss: 7.6121 - val_acc: 0.0703\n",
            "Epoch 557/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.8130 - acc: 0.5273 - val_loss: 7.6088 - val_acc: 0.0683\n",
            "Epoch 558/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8127 - acc: 0.5278 - val_loss: 7.6240 - val_acc: 0.0692\n",
            "Epoch 559/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.8100 - acc: 0.5268 - val_loss: 7.6201 - val_acc: 0.0686\n",
            "Epoch 560/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.8095 - acc: 0.5278 - val_loss: 7.6266 - val_acc: 0.0694\n",
            "Epoch 561/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8105 - acc: 0.5273 - val_loss: 7.6226 - val_acc: 0.0706\n",
            "Epoch 562/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8091 - acc: 0.5277 - val_loss: 7.6286 - val_acc: 0.0663\n",
            "Epoch 563/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8104 - acc: 0.5273 - val_loss: 7.6262 - val_acc: 0.0697\n",
            "Epoch 564/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8110 - acc: 0.5279 - val_loss: 7.6370 - val_acc: 0.0689\n",
            "Epoch 565/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8136 - acc: 0.5273 - val_loss: 7.6255 - val_acc: 0.0692\n",
            "Epoch 566/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8144 - acc: 0.5258 - val_loss: 7.6348 - val_acc: 0.0689\n",
            "Epoch 567/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8136 - acc: 0.5272 - val_loss: 7.6281 - val_acc: 0.0689\n",
            "Epoch 568/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8157 - acc: 0.5242 - val_loss: 7.6403 - val_acc: 0.0697\n",
            "Epoch 569/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8148 - acc: 0.5262 - val_loss: 7.6385 - val_acc: 0.0712\n",
            "Epoch 570/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8135 - acc: 0.5254 - val_loss: 7.6359 - val_acc: 0.0715\n",
            "Epoch 571/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.8124 - acc: 0.5271 - val_loss: 7.6390 - val_acc: 0.0694\n",
            "Epoch 572/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8123 - acc: 0.5258 - val_loss: 7.6359 - val_acc: 0.0703\n",
            "Epoch 573/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.8124 - acc: 0.5262 - val_loss: 7.6430 - val_acc: 0.0686\n",
            "Epoch 574/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8148 - acc: 0.5254 - val_loss: 7.6465 - val_acc: 0.0694\n",
            "Epoch 575/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8186 - acc: 0.5242 - val_loss: 7.6412 - val_acc: 0.0680\n",
            "Epoch 576/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8147 - acc: 0.5241 - val_loss: 7.6412 - val_acc: 0.0706\n",
            "Epoch 577/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8122 - acc: 0.5249 - val_loss: 7.6745 - val_acc: 0.0674\n",
            "Epoch 578/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8134 - acc: 0.5239 - val_loss: 7.6643 - val_acc: 0.0689\n",
            "Epoch 579/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.8162 - acc: 0.5260 - val_loss: 7.6675 - val_acc: 0.0692\n",
            "Epoch 580/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8155 - acc: 0.5253 - val_loss: 7.6578 - val_acc: 0.0712\n",
            "Epoch 581/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8142 - acc: 0.5256 - val_loss: 7.6692 - val_acc: 0.0694\n",
            "Epoch 582/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8112 - acc: 0.5254 - val_loss: 7.6658 - val_acc: 0.0700\n",
            "Epoch 583/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8089 - acc: 0.5266 - val_loss: 7.6608 - val_acc: 0.0668\n",
            "Epoch 584/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.8070 - acc: 0.5279 - val_loss: 7.6753 - val_acc: 0.0700\n",
            "Epoch 585/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8050 - acc: 0.5287 - val_loss: 7.6748 - val_acc: 0.0689\n",
            "Epoch 586/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.8014 - acc: 0.5293 - val_loss: 7.6755 - val_acc: 0.0697\n",
            "Epoch 587/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8003 - acc: 0.5287 - val_loss: 7.6786 - val_acc: 0.0689\n",
            "Epoch 588/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7966 - acc: 0.5306 - val_loss: 7.6780 - val_acc: 0.0677\n",
            "Epoch 589/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7967 - acc: 0.5295 - val_loss: 7.6816 - val_acc: 0.0700\n",
            "Epoch 590/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7966 - acc: 0.5305 - val_loss: 7.6885 - val_acc: 0.0683\n",
            "Epoch 591/1000\n",
            "1148/1148 [==============================] - 0s 307us/step - loss: 0.7980 - acc: 0.5300 - val_loss: 7.6892 - val_acc: 0.0697\n",
            "Epoch 592/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 0.7991 - acc: 0.5295 - val_loss: 7.6784 - val_acc: 0.0697\n",
            "Epoch 593/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.8009 - acc: 0.5276 - val_loss: 7.7000 - val_acc: 0.0694\n",
            "Epoch 594/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8004 - acc: 0.5292 - val_loss: 7.6876 - val_acc: 0.0694\n",
            "Epoch 595/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8029 - acc: 0.5295 - val_loss: 7.7100 - val_acc: 0.0712\n",
            "Epoch 596/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8125 - acc: 0.5264 - val_loss: 7.6977 - val_acc: 0.0706\n",
            "Epoch 597/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8189 - acc: 0.5237 - val_loss: 7.7037 - val_acc: 0.0712\n",
            "Epoch 598/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8153 - acc: 0.5237 - val_loss: 7.6923 - val_acc: 0.0720\n",
            "Epoch 599/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8228 - acc: 0.5220 - val_loss: 7.6988 - val_acc: 0.0723\n",
            "Epoch 600/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.8253 - acc: 0.5195 - val_loss: 7.6935 - val_acc: 0.0706\n",
            "Epoch 601/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.8231 - acc: 0.5217 - val_loss: 7.7211 - val_acc: 0.0703\n",
            "Epoch 602/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8162 - acc: 0.5234 - val_loss: 7.6998 - val_acc: 0.0726\n",
            "Epoch 603/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.8145 - acc: 0.5238 - val_loss: 7.7099 - val_acc: 0.0697\n",
            "Epoch 604/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.8113 - acc: 0.5216 - val_loss: 7.7089 - val_acc: 0.0706\n",
            "Epoch 605/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.8067 - acc: 0.5252 - val_loss: 7.7094 - val_acc: 0.0683\n",
            "Epoch 606/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8043 - acc: 0.5267 - val_loss: 7.7265 - val_acc: 0.0709\n",
            "Epoch 607/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.8030 - acc: 0.5277 - val_loss: 7.7185 - val_acc: 0.0715\n",
            "Epoch 608/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.8013 - acc: 0.5277 - val_loss: 7.7299 - val_acc: 0.0712\n",
            "Epoch 609/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7988 - acc: 0.5274 - val_loss: 7.7384 - val_acc: 0.0700\n",
            "Epoch 610/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7960 - acc: 0.5309 - val_loss: 7.7252 - val_acc: 0.0706\n",
            "Epoch 611/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7957 - acc: 0.5282 - val_loss: 7.7124 - val_acc: 0.0726\n",
            "Epoch 612/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7932 - acc: 0.5297 - val_loss: 7.7289 - val_acc: 0.0689\n",
            "Epoch 613/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7969 - acc: 0.5274 - val_loss: 7.7275 - val_acc: 0.0700\n",
            "Epoch 614/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7995 - acc: 0.5280 - val_loss: 7.7219 - val_acc: 0.0697\n",
            "Epoch 615/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.8086 - acc: 0.5234 - val_loss: 7.7230 - val_acc: 0.0709\n",
            "Epoch 616/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8204 - acc: 0.5207 - val_loss: 7.7187 - val_acc: 0.0703\n",
            "Epoch 617/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.8190 - acc: 0.5213 - val_loss: 7.7247 - val_acc: 0.0686\n",
            "Epoch 618/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.8119 - acc: 0.5228 - val_loss: 7.7195 - val_acc: 0.0694\n",
            "Epoch 619/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.8074 - acc: 0.5248 - val_loss: 7.7261 - val_acc: 0.0706\n",
            "Epoch 620/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8029 - acc: 0.5274 - val_loss: 7.7317 - val_acc: 0.0706\n",
            "Epoch 621/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8068 - acc: 0.5258 - val_loss: 7.7290 - val_acc: 0.0703\n",
            "Epoch 622/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.8118 - acc: 0.5232 - val_loss: 7.7260 - val_acc: 0.0729\n",
            "Epoch 623/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.8168 - acc: 0.5215 - val_loss: 7.7386 - val_acc: 0.0718\n",
            "Epoch 624/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.8128 - acc: 0.5240 - val_loss: 7.7383 - val_acc: 0.0715\n",
            "Epoch 625/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.8046 - acc: 0.5254 - val_loss: 7.7410 - val_acc: 0.0715\n",
            "Epoch 626/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7983 - acc: 0.5272 - val_loss: 7.7441 - val_acc: 0.0735\n",
            "Epoch 627/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7950 - acc: 0.5268 - val_loss: 7.7442 - val_acc: 0.0715\n",
            "Epoch 628/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7936 - acc: 0.5286 - val_loss: 7.7488 - val_acc: 0.0715\n",
            "Epoch 629/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7918 - acc: 0.5301 - val_loss: 7.7406 - val_acc: 0.0712\n",
            "Epoch 630/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7891 - acc: 0.5295 - val_loss: 7.7562 - val_acc: 0.0718\n",
            "Epoch 631/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 0.7858 - acc: 0.5308 - val_loss: 7.7518 - val_acc: 0.0720\n",
            "Epoch 632/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7837 - acc: 0.5316 - val_loss: 7.7562 - val_acc: 0.0720\n",
            "Epoch 633/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7804 - acc: 0.5329 - val_loss: 7.7641 - val_acc: 0.0715\n",
            "Epoch 634/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7794 - acc: 0.5326 - val_loss: 7.7674 - val_acc: 0.0706\n",
            "Epoch 635/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7782 - acc: 0.5330 - val_loss: 7.7772 - val_acc: 0.0718\n",
            "Epoch 636/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7796 - acc: 0.5332 - val_loss: 7.7677 - val_acc: 0.0715\n",
            "Epoch 637/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7821 - acc: 0.5306 - val_loss: 7.7647 - val_acc: 0.0718\n",
            "Epoch 638/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7824 - acc: 0.5316 - val_loss: 7.7680 - val_acc: 0.0715\n",
            "Epoch 639/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7809 - acc: 0.5319 - val_loss: 7.7511 - val_acc: 0.0712\n",
            "Epoch 640/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7821 - acc: 0.5325 - val_loss: 7.7654 - val_acc: 0.0706\n",
            "Epoch 641/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7820 - acc: 0.5307 - val_loss: 7.7667 - val_acc: 0.0683\n",
            "Epoch 642/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7800 - acc: 0.5324 - val_loss: 7.7750 - val_acc: 0.0712\n",
            "Epoch 643/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7784 - acc: 0.5317 - val_loss: 7.7774 - val_acc: 0.0709\n",
            "Epoch 644/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7754 - acc: 0.5337 - val_loss: 7.7884 - val_acc: 0.0700\n",
            "Epoch 645/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.7742 - acc: 0.5332 - val_loss: 7.7806 - val_acc: 0.0715\n",
            "Epoch 646/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7730 - acc: 0.5347 - val_loss: 7.7841 - val_acc: 0.0715\n",
            "Epoch 647/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7707 - acc: 0.5350 - val_loss: 7.7764 - val_acc: 0.0715\n",
            "Epoch 648/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7708 - acc: 0.5355 - val_loss: 7.7814 - val_acc: 0.0709\n",
            "Epoch 649/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7692 - acc: 0.5354 - val_loss: 7.7836 - val_acc: 0.0694\n",
            "Epoch 650/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.7701 - acc: 0.5338 - val_loss: 7.7843 - val_acc: 0.0703\n",
            "Epoch 651/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7723 - acc: 0.5332 - val_loss: 7.7911 - val_acc: 0.0697\n",
            "Epoch 652/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7712 - acc: 0.5343 - val_loss: 7.7867 - val_acc: 0.0700\n",
            "Epoch 653/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7709 - acc: 0.5347 - val_loss: 7.7880 - val_acc: 0.0700\n",
            "Epoch 654/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7693 - acc: 0.5348 - val_loss: 7.7968 - val_acc: 0.0709\n",
            "Epoch 655/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7680 - acc: 0.5360 - val_loss: 7.7967 - val_acc: 0.0703\n",
            "Epoch 656/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7672 - acc: 0.5354 - val_loss: 7.7952 - val_acc: 0.0697\n",
            "Epoch 657/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7666 - acc: 0.5348 - val_loss: 7.7908 - val_acc: 0.0712\n",
            "Epoch 658/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7671 - acc: 0.5354 - val_loss: 7.7991 - val_acc: 0.0709\n",
            "Epoch 659/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7662 - acc: 0.5351 - val_loss: 7.8015 - val_acc: 0.0709\n",
            "Epoch 660/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7653 - acc: 0.5368 - val_loss: 7.7971 - val_acc: 0.0703\n",
            "Epoch 661/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 0.7642 - acc: 0.5354 - val_loss: 7.7957 - val_acc: 0.0692\n",
            "Epoch 662/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 0.7633 - acc: 0.5361 - val_loss: 7.8063 - val_acc: 0.0692\n",
            "Epoch 663/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7634 - acc: 0.5363 - val_loss: 7.7983 - val_acc: 0.0700\n",
            "Epoch 664/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7636 - acc: 0.5365 - val_loss: 7.8039 - val_acc: 0.0700\n",
            "Epoch 665/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7630 - acc: 0.5352 - val_loss: 7.7991 - val_acc: 0.0697\n",
            "Epoch 666/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7644 - acc: 0.5360 - val_loss: 7.8010 - val_acc: 0.0694\n",
            "Epoch 667/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7632 - acc: 0.5354 - val_loss: 7.8100 - val_acc: 0.0686\n",
            "Epoch 668/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7624 - acc: 0.5366 - val_loss: 7.8046 - val_acc: 0.0700\n",
            "Epoch 669/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7632 - acc: 0.5348 - val_loss: 7.8171 - val_acc: 0.0686\n",
            "Epoch 670/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7641 - acc: 0.5353 - val_loss: 7.8189 - val_acc: 0.0692\n",
            "Epoch 671/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7650 - acc: 0.5352 - val_loss: 7.8041 - val_acc: 0.0689\n",
            "Epoch 672/1000\n",
            "1148/1148 [==============================] - 0s 337us/step - loss: 0.7625 - acc: 0.5351 - val_loss: 7.8150 - val_acc: 0.0697\n",
            "Epoch 673/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7633 - acc: 0.5352 - val_loss: 7.8179 - val_acc: 0.0692\n",
            "Epoch 674/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7622 - acc: 0.5361 - val_loss: 7.8080 - val_acc: 0.0689\n",
            "Epoch 675/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7610 - acc: 0.5372 - val_loss: 7.8135 - val_acc: 0.0706\n",
            "Epoch 676/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7622 - acc: 0.5354 - val_loss: 7.8135 - val_acc: 0.0694\n",
            "Epoch 677/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7632 - acc: 0.5365 - val_loss: 7.8046 - val_acc: 0.0709\n",
            "Epoch 678/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7663 - acc: 0.5356 - val_loss: 7.8166 - val_acc: 0.0700\n",
            "Epoch 679/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7663 - acc: 0.5348 - val_loss: 7.8164 - val_acc: 0.0709\n",
            "Epoch 680/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.7658 - acc: 0.5340 - val_loss: 7.8158 - val_acc: 0.0697\n",
            "Epoch 681/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7638 - acc: 0.5361 - val_loss: 7.8248 - val_acc: 0.0706\n",
            "Epoch 682/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7639 - acc: 0.5358 - val_loss: 7.8352 - val_acc: 0.0692\n",
            "Epoch 683/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 0.7664 - acc: 0.5350 - val_loss: 7.8349 - val_acc: 0.0703\n",
            "Epoch 684/1000\n",
            "1148/1148 [==============================] - 0s 339us/step - loss: 0.7691 - acc: 0.5343 - val_loss: 7.8413 - val_acc: 0.0692\n",
            "Epoch 685/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7670 - acc: 0.5353 - val_loss: 7.8397 - val_acc: 0.0686\n",
            "Epoch 686/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7637 - acc: 0.5351 - val_loss: 7.8569 - val_acc: 0.0692\n",
            "Epoch 687/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7625 - acc: 0.5354 - val_loss: 7.8585 - val_acc: 0.0674\n",
            "Epoch 688/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7615 - acc: 0.5362 - val_loss: 7.8346 - val_acc: 0.0683\n",
            "Epoch 689/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7643 - acc: 0.5351 - val_loss: 7.8502 - val_acc: 0.0686\n",
            "Epoch 690/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7647 - acc: 0.5349 - val_loss: 7.8512 - val_acc: 0.0677\n",
            "Epoch 691/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7648 - acc: 0.5356 - val_loss: 7.8429 - val_acc: 0.0674\n",
            "Epoch 692/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7633 - acc: 0.5349 - val_loss: 7.8464 - val_acc: 0.0689\n",
            "Epoch 693/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7620 - acc: 0.5338 - val_loss: 7.8502 - val_acc: 0.0700\n",
            "Epoch 694/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7607 - acc: 0.5359 - val_loss: 7.8571 - val_acc: 0.0663\n",
            "Epoch 695/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7584 - acc: 0.5370 - val_loss: 7.8631 - val_acc: 0.0677\n",
            "Epoch 696/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7571 - acc: 0.5367 - val_loss: 7.8606 - val_acc: 0.0680\n",
            "Epoch 697/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7543 - acc: 0.5367 - val_loss: 7.8664 - val_acc: 0.0683\n",
            "Epoch 698/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7543 - acc: 0.5377 - val_loss: 7.8648 - val_acc: 0.0692\n",
            "Epoch 699/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7533 - acc: 0.5369 - val_loss: 7.8660 - val_acc: 0.0680\n",
            "Epoch 700/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.7526 - acc: 0.5384 - val_loss: 7.8719 - val_acc: 0.0674\n",
            "Epoch 701/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7512 - acc: 0.5385 - val_loss: 7.8701 - val_acc: 0.0683\n",
            "Epoch 702/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7508 - acc: 0.5388 - val_loss: 7.8778 - val_acc: 0.0666\n",
            "Epoch 703/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7508 - acc: 0.5375 - val_loss: 7.8827 - val_acc: 0.0683\n",
            "Epoch 704/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7504 - acc: 0.5390 - val_loss: 7.8721 - val_acc: 0.0680\n",
            "Epoch 705/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7492 - acc: 0.5395 - val_loss: 7.8752 - val_acc: 0.0677\n",
            "Epoch 706/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7491 - acc: 0.5384 - val_loss: 7.8880 - val_acc: 0.0686\n",
            "Epoch 707/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7507 - acc: 0.5397 - val_loss: 7.8818 - val_acc: 0.0677\n",
            "Epoch 708/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7498 - acc: 0.5380 - val_loss: 7.8800 - val_acc: 0.0689\n",
            "Epoch 709/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7513 - acc: 0.5377 - val_loss: 7.8865 - val_acc: 0.0683\n",
            "Epoch 710/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7512 - acc: 0.5388 - val_loss: 7.8911 - val_acc: 0.0683\n",
            "Epoch 711/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7503 - acc: 0.5390 - val_loss: 7.8833 - val_acc: 0.0692\n",
            "Epoch 712/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7485 - acc: 0.5389 - val_loss: 7.8737 - val_acc: 0.0700\n",
            "Epoch 713/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7478 - acc: 0.5393 - val_loss: 7.8792 - val_acc: 0.0709\n",
            "Epoch 714/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7466 - acc: 0.5404 - val_loss: 7.8702 - val_acc: 0.0700\n",
            "Epoch 715/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7466 - acc: 0.5394 - val_loss: 7.8767 - val_acc: 0.0709\n",
            "Epoch 716/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7481 - acc: 0.5387 - val_loss: 7.8803 - val_acc: 0.0686\n",
            "Epoch 717/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7486 - acc: 0.5401 - val_loss: 7.8776 - val_acc: 0.0694\n",
            "Epoch 718/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7493 - acc: 0.5377 - val_loss: 7.8830 - val_acc: 0.0703\n",
            "Epoch 719/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7530 - acc: 0.5359 - val_loss: 7.8784 - val_acc: 0.0712\n",
            "Epoch 720/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.7516 - acc: 0.5369 - val_loss: 7.8823 - val_acc: 0.0700\n",
            "Epoch 721/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7518 - acc: 0.5378 - val_loss: 7.8887 - val_acc: 0.0703\n",
            "Epoch 722/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7542 - acc: 0.5359 - val_loss: 7.8903 - val_acc: 0.0720\n",
            "Epoch 723/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7530 - acc: 0.5377 - val_loss: 7.8985 - val_acc: 0.0689\n",
            "Epoch 724/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7524 - acc: 0.5378 - val_loss: 7.8920 - val_acc: 0.0683\n",
            "Epoch 725/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7544 - acc: 0.5351 - val_loss: 7.9060 - val_acc: 0.0692\n",
            "Epoch 726/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7547 - acc: 0.5368 - val_loss: 7.9130 - val_acc: 0.0689\n",
            "Epoch 727/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7565 - acc: 0.5343 - val_loss: 7.9069 - val_acc: 0.0689\n",
            "Epoch 728/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7612 - acc: 0.5343 - val_loss: 7.9104 - val_acc: 0.0677\n",
            "Epoch 729/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.7599 - acc: 0.5354 - val_loss: 7.9084 - val_acc: 0.0671\n",
            "Epoch 730/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7662 - acc: 0.5316 - val_loss: 7.9158 - val_acc: 0.0703\n",
            "Epoch 731/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7671 - acc: 0.5322 - val_loss: 7.8986 - val_acc: 0.0694\n",
            "Epoch 732/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7662 - acc: 0.5320 - val_loss: 7.9158 - val_acc: 0.0694\n",
            "Epoch 733/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7691 - acc: 0.5332 - val_loss: 7.9091 - val_acc: 0.0692\n",
            "Epoch 734/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7666 - acc: 0.5319 - val_loss: 7.9013 - val_acc: 0.0694\n",
            "Epoch 735/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7679 - acc: 0.5322 - val_loss: 7.9240 - val_acc: 0.0671\n",
            "Epoch 736/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7623 - acc: 0.5338 - val_loss: 7.9331 - val_acc: 0.0674\n",
            "Epoch 737/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7584 - acc: 0.5355 - val_loss: 7.9159 - val_acc: 0.0686\n",
            "Epoch 738/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7565 - acc: 0.5358 - val_loss: 7.9284 - val_acc: 0.0697\n",
            "Epoch 739/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7516 - acc: 0.5373 - val_loss: 7.8969 - val_acc: 0.0697\n",
            "Epoch 740/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7495 - acc: 0.5385 - val_loss: 7.9213 - val_acc: 0.0694\n",
            "Epoch 741/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7482 - acc: 0.5391 - val_loss: 7.9236 - val_acc: 0.0683\n",
            "Epoch 742/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7460 - acc: 0.5391 - val_loss: 7.9172 - val_acc: 0.0697\n",
            "Epoch 743/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7457 - acc: 0.5368 - val_loss: 7.9180 - val_acc: 0.0700\n",
            "Epoch 744/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7465 - acc: 0.5393 - val_loss: 7.9235 - val_acc: 0.0709\n",
            "Epoch 745/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7447 - acc: 0.5409 - val_loss: 7.9373 - val_acc: 0.0689\n",
            "Epoch 746/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7440 - acc: 0.5393 - val_loss: 7.9290 - val_acc: 0.0694\n",
            "Epoch 747/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7440 - acc: 0.5403 - val_loss: 7.9372 - val_acc: 0.0680\n",
            "Epoch 748/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7429 - acc: 0.5394 - val_loss: 7.9350 - val_acc: 0.0671\n",
            "Epoch 749/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7456 - acc: 0.5396 - val_loss: 7.9225 - val_acc: 0.0703\n",
            "Epoch 750/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7431 - acc: 0.5393 - val_loss: 7.9354 - val_acc: 0.0697\n",
            "Epoch 751/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7456 - acc: 0.5384 - val_loss: 7.9264 - val_acc: 0.0697\n",
            "Epoch 752/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7424 - acc: 0.5396 - val_loss: 7.9301 - val_acc: 0.0686\n",
            "Epoch 753/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7423 - acc: 0.5409 - val_loss: 7.9248 - val_acc: 0.0686\n",
            "Epoch 754/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7396 - acc: 0.5406 - val_loss: 7.9336 - val_acc: 0.0683\n",
            "Epoch 755/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7384 - acc: 0.5404 - val_loss: 7.9391 - val_acc: 0.0668\n",
            "Epoch 756/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7368 - acc: 0.5412 - val_loss: 7.9419 - val_acc: 0.0680\n",
            "Epoch 757/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7354 - acc: 0.5418 - val_loss: 7.9485 - val_acc: 0.0677\n",
            "Epoch 758/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7338 - acc: 0.5420 - val_loss: 7.9488 - val_acc: 0.0674\n",
            "Epoch 759/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7349 - acc: 0.5403 - val_loss: 7.9433 - val_acc: 0.0686\n",
            "Epoch 760/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7331 - acc: 0.5420 - val_loss: 7.9512 - val_acc: 0.0683\n",
            "Epoch 761/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7324 - acc: 0.5428 - val_loss: 7.9479 - val_acc: 0.0694\n",
            "Epoch 762/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7356 - acc: 0.5411 - val_loss: 7.9582 - val_acc: 0.0686\n",
            "Epoch 763/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7372 - acc: 0.5402 - val_loss: 7.9509 - val_acc: 0.0683\n",
            "Epoch 764/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7374 - acc: 0.5401 - val_loss: 7.9501 - val_acc: 0.0686\n",
            "Epoch 765/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7366 - acc: 0.5404 - val_loss: 7.9485 - val_acc: 0.0680\n",
            "Epoch 766/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.7372 - acc: 0.5416 - val_loss: 7.9604 - val_acc: 0.0668\n",
            "Epoch 767/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7386 - acc: 0.5407 - val_loss: 7.9528 - val_acc: 0.0674\n",
            "Epoch 768/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7389 - acc: 0.5393 - val_loss: 7.9672 - val_acc: 0.0666\n",
            "Epoch 769/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7398 - acc: 0.5394 - val_loss: 7.9469 - val_acc: 0.0663\n",
            "Epoch 770/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7485 - acc: 0.5357 - val_loss: 7.9325 - val_acc: 0.0680\n",
            "Epoch 771/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7606 - acc: 0.5333 - val_loss: 7.9572 - val_acc: 0.0694\n",
            "Epoch 772/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7634 - acc: 0.5320 - val_loss: 7.9416 - val_acc: 0.0692\n",
            "Epoch 773/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7599 - acc: 0.5327 - val_loss: 7.9498 - val_acc: 0.0694\n",
            "Epoch 774/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7610 - acc: 0.5333 - val_loss: 7.9393 - val_acc: 0.0674\n",
            "Epoch 775/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7597 - acc: 0.5346 - val_loss: 7.9601 - val_acc: 0.0697\n",
            "Epoch 776/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7577 - acc: 0.5345 - val_loss: 7.9623 - val_acc: 0.0677\n",
            "Epoch 777/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7554 - acc: 0.5354 - val_loss: 7.9583 - val_acc: 0.0668\n",
            "Epoch 778/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7541 - acc: 0.5341 - val_loss: 7.9622 - val_acc: 0.0689\n",
            "Epoch 779/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7507 - acc: 0.5365 - val_loss: 7.9657 - val_acc: 0.0686\n",
            "Epoch 780/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7572 - acc: 0.5348 - val_loss: 7.9681 - val_acc: 0.0671\n",
            "Epoch 781/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7599 - acc: 0.5335 - val_loss: 7.9781 - val_acc: 0.0674\n",
            "Epoch 782/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7603 - acc: 0.5344 - val_loss: 7.9576 - val_acc: 0.0697\n",
            "Epoch 783/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7601 - acc: 0.5348 - val_loss: 7.9819 - val_acc: 0.0694\n",
            "Epoch 784/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7538 - acc: 0.5355 - val_loss: 7.9638 - val_acc: 0.0689\n",
            "Epoch 785/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.7451 - acc: 0.5383 - val_loss: 7.9709 - val_acc: 0.0703\n",
            "Epoch 786/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7395 - acc: 0.5404 - val_loss: 7.9814 - val_acc: 0.0680\n",
            "Epoch 787/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7366 - acc: 0.5404 - val_loss: 7.9732 - val_acc: 0.0700\n",
            "Epoch 788/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7356 - acc: 0.5411 - val_loss: 7.9722 - val_acc: 0.0692\n",
            "Epoch 789/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7332 - acc: 0.5420 - val_loss: 7.9723 - val_acc: 0.0689\n",
            "Epoch 790/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7342 - acc: 0.5407 - val_loss: 7.9777 - val_acc: 0.0686\n",
            "Epoch 791/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7315 - acc: 0.5422 - val_loss: 7.9779 - val_acc: 0.0671\n",
            "Epoch 792/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7297 - acc: 0.5432 - val_loss: 7.9785 - val_acc: 0.0680\n",
            "Epoch 793/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7285 - acc: 0.5425 - val_loss: 7.9836 - val_acc: 0.0686\n",
            "Epoch 794/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7289 - acc: 0.5414 - val_loss: 7.9785 - val_acc: 0.0689\n",
            "Epoch 795/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.7284 - acc: 0.5422 - val_loss: 7.9904 - val_acc: 0.0694\n",
            "Epoch 796/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7279 - acc: 0.5427 - val_loss: 7.9897 - val_acc: 0.0683\n",
            "Epoch 797/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7273 - acc: 0.5422 - val_loss: 7.9847 - val_acc: 0.0694\n",
            "Epoch 798/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7272 - acc: 0.5417 - val_loss: 7.9914 - val_acc: 0.0683\n",
            "Epoch 799/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7281 - acc: 0.5425 - val_loss: 7.9859 - val_acc: 0.0680\n",
            "Epoch 800/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7271 - acc: 0.5434 - val_loss: 7.9788 - val_acc: 0.0686\n",
            "Epoch 801/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7269 - acc: 0.5441 - val_loss: 7.9868 - val_acc: 0.0694\n",
            "Epoch 802/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7263 - acc: 0.5428 - val_loss: 7.9826 - val_acc: 0.0694\n",
            "Epoch 803/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7238 - acc: 0.5436 - val_loss: 7.9847 - val_acc: 0.0677\n",
            "Epoch 804/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7224 - acc: 0.5437 - val_loss: 8.0004 - val_acc: 0.0677\n",
            "Epoch 805/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7234 - acc: 0.5430 - val_loss: 8.0004 - val_acc: 0.0697\n",
            "Epoch 806/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7229 - acc: 0.5440 - val_loss: 7.9922 - val_acc: 0.0697\n",
            "Epoch 807/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7218 - acc: 0.5442 - val_loss: 7.9935 - val_acc: 0.0680\n",
            "Epoch 808/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7219 - acc: 0.5450 - val_loss: 8.0039 - val_acc: 0.0683\n",
            "Epoch 809/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7208 - acc: 0.5440 - val_loss: 8.0102 - val_acc: 0.0686\n",
            "Epoch 810/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7208 - acc: 0.5434 - val_loss: 7.9949 - val_acc: 0.0692\n",
            "Epoch 811/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7261 - acc: 0.5431 - val_loss: 7.9989 - val_acc: 0.0692\n",
            "Epoch 812/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7249 - acc: 0.5404 - val_loss: 8.0003 - val_acc: 0.0677\n",
            "Epoch 813/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7230 - acc: 0.5431 - val_loss: 7.9960 - val_acc: 0.0683\n",
            "Epoch 814/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7220 - acc: 0.5433 - val_loss: 7.9963 - val_acc: 0.0697\n",
            "Epoch 815/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7229 - acc: 0.5437 - val_loss: 7.9924 - val_acc: 0.0703\n",
            "Epoch 816/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7236 - acc: 0.5422 - val_loss: 8.0070 - val_acc: 0.0689\n",
            "Epoch 817/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7253 - acc: 0.5431 - val_loss: 8.0072 - val_acc: 0.0709\n",
            "Epoch 818/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7236 - acc: 0.5422 - val_loss: 8.0052 - val_acc: 0.0689\n",
            "Epoch 819/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7267 - acc: 0.5429 - val_loss: 8.0001 - val_acc: 0.0694\n",
            "Epoch 820/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7298 - acc: 0.5419 - val_loss: 7.9917 - val_acc: 0.0712\n",
            "Epoch 821/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7351 - acc: 0.5393 - val_loss: 8.0048 - val_acc: 0.0692\n",
            "Epoch 822/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7367 - acc: 0.5381 - val_loss: 8.0071 - val_acc: 0.0718\n",
            "Epoch 823/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.7426 - acc: 0.5364 - val_loss: 7.9936 - val_acc: 0.0700\n",
            "Epoch 824/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7440 - acc: 0.5367 - val_loss: 7.9988 - val_acc: 0.0697\n",
            "Epoch 825/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7423 - acc: 0.5375 - val_loss: 7.9946 - val_acc: 0.0712\n",
            "Epoch 826/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7374 - acc: 0.5385 - val_loss: 7.9843 - val_acc: 0.0726\n",
            "Epoch 827/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7361 - acc: 0.5382 - val_loss: 7.9945 - val_acc: 0.0720\n",
            "Epoch 828/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7345 - acc: 0.5395 - val_loss: 7.9983 - val_acc: 0.0718\n",
            "Epoch 829/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7438 - acc: 0.5377 - val_loss: 7.9887 - val_acc: 0.0712\n",
            "Epoch 830/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7475 - acc: 0.5349 - val_loss: 8.0012 - val_acc: 0.0694\n",
            "Epoch 831/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7512 - acc: 0.5354 - val_loss: 7.9884 - val_acc: 0.0709\n",
            "Epoch 832/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.7474 - acc: 0.5351 - val_loss: 7.9932 - val_acc: 0.0700\n",
            "Epoch 833/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7442 - acc: 0.5389 - val_loss: 8.0038 - val_acc: 0.0718\n",
            "Epoch 834/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7417 - acc: 0.5396 - val_loss: 7.9892 - val_acc: 0.0677\n",
            "Epoch 835/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7454 - acc: 0.5374 - val_loss: 8.0012 - val_acc: 0.0703\n",
            "Epoch 836/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7430 - acc: 0.5377 - val_loss: 7.9984 - val_acc: 0.0703\n",
            "Epoch 837/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.7409 - acc: 0.5373 - val_loss: 7.9969 - val_acc: 0.0715\n",
            "Epoch 838/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7396 - acc: 0.5380 - val_loss: 7.9917 - val_acc: 0.0694\n",
            "Epoch 839/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7354 - acc: 0.5396 - val_loss: 8.0023 - val_acc: 0.0700\n",
            "Epoch 840/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7295 - acc: 0.5413 - val_loss: 7.9947 - val_acc: 0.0703\n",
            "Epoch 841/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7278 - acc: 0.5414 - val_loss: 8.0010 - val_acc: 0.0709\n",
            "Epoch 842/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7263 - acc: 0.5411 - val_loss: 8.0079 - val_acc: 0.0715\n",
            "Epoch 843/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7236 - acc: 0.5420 - val_loss: 8.0036 - val_acc: 0.0703\n",
            "Epoch 844/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7219 - acc: 0.5430 - val_loss: 7.9999 - val_acc: 0.0715\n",
            "Epoch 845/1000\n",
            "1148/1148 [==============================] - 0s 330us/step - loss: 0.7217 - acc: 0.5430 - val_loss: 8.0067 - val_acc: 0.0709\n",
            "Epoch 846/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7199 - acc: 0.5441 - val_loss: 8.0084 - val_acc: 0.0700\n",
            "Epoch 847/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7190 - acc: 0.5436 - val_loss: 8.0168 - val_acc: 0.0697\n",
            "Epoch 848/1000\n",
            "1148/1148 [==============================] - 0s 335us/step - loss: 0.7182 - acc: 0.5433 - val_loss: 8.0155 - val_acc: 0.0700\n",
            "Epoch 849/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7182 - acc: 0.5432 - val_loss: 8.0153 - val_acc: 0.0712\n",
            "Epoch 850/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7176 - acc: 0.5441 - val_loss: 8.0187 - val_acc: 0.0703\n",
            "Epoch 851/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7173 - acc: 0.5437 - val_loss: 8.0310 - val_acc: 0.0709\n",
            "Epoch 852/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7180 - acc: 0.5433 - val_loss: 8.0275 - val_acc: 0.0706\n",
            "Epoch 853/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7168 - acc: 0.5433 - val_loss: 8.0305 - val_acc: 0.0694\n",
            "Epoch 854/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7183 - acc: 0.5442 - val_loss: 8.0291 - val_acc: 0.0712\n",
            "Epoch 855/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7181 - acc: 0.5436 - val_loss: 8.0314 - val_acc: 0.0712\n",
            "Epoch 856/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7167 - acc: 0.5435 - val_loss: 8.0438 - val_acc: 0.0700\n",
            "Epoch 857/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7151 - acc: 0.5448 - val_loss: 8.0563 - val_acc: 0.0700\n",
            "Epoch 858/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7148 - acc: 0.5448 - val_loss: 8.0469 - val_acc: 0.0689\n",
            "Epoch 859/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7139 - acc: 0.5444 - val_loss: 8.0502 - val_acc: 0.0677\n",
            "Epoch 860/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7135 - acc: 0.5442 - val_loss: 8.0480 - val_acc: 0.0703\n",
            "Epoch 861/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7145 - acc: 0.5452 - val_loss: 8.0439 - val_acc: 0.0686\n",
            "Epoch 862/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7159 - acc: 0.5436 - val_loss: 8.0519 - val_acc: 0.0694\n",
            "Epoch 863/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.7185 - acc: 0.5430 - val_loss: 8.0525 - val_acc: 0.0703\n",
            "Epoch 864/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7154 - acc: 0.5440 - val_loss: 8.0584 - val_acc: 0.0709\n",
            "Epoch 865/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7176 - acc: 0.5439 - val_loss: 8.0583 - val_acc: 0.0692\n",
            "Epoch 866/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7155 - acc: 0.5449 - val_loss: 8.0577 - val_acc: 0.0703\n",
            "Epoch 867/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7183 - acc: 0.5436 - val_loss: 8.0527 - val_acc: 0.0703\n",
            "Epoch 868/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7169 - acc: 0.5438 - val_loss: 8.0559 - val_acc: 0.0692\n",
            "Epoch 869/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7148 - acc: 0.5437 - val_loss: 8.0570 - val_acc: 0.0700\n",
            "Epoch 870/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7148 - acc: 0.5427 - val_loss: 8.0556 - val_acc: 0.0694\n",
            "Epoch 871/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7123 - acc: 0.5460 - val_loss: 8.0507 - val_acc: 0.0694\n",
            "Epoch 872/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7122 - acc: 0.5453 - val_loss: 8.0569 - val_acc: 0.0697\n",
            "Epoch 873/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7119 - acc: 0.5449 - val_loss: 8.0589 - val_acc: 0.0697\n",
            "Epoch 874/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7107 - acc: 0.5452 - val_loss: 8.0561 - val_acc: 0.0683\n",
            "Epoch 875/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7113 - acc: 0.5458 - val_loss: 8.0539 - val_acc: 0.0703\n",
            "Epoch 876/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7116 - acc: 0.5436 - val_loss: 8.0705 - val_acc: 0.0689\n",
            "Epoch 877/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7115 - acc: 0.5434 - val_loss: 8.0768 - val_acc: 0.0697\n",
            "Epoch 878/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7092 - acc: 0.5465 - val_loss: 8.0753 - val_acc: 0.0677\n",
            "Epoch 879/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7088 - acc: 0.5450 - val_loss: 8.0727 - val_acc: 0.0689\n",
            "Epoch 880/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7084 - acc: 0.5439 - val_loss: 8.0802 - val_acc: 0.0689\n",
            "Epoch 881/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7083 - acc: 0.5446 - val_loss: 8.0762 - val_acc: 0.0689\n",
            "Epoch 882/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7075 - acc: 0.5465 - val_loss: 8.0780 - val_acc: 0.0686\n",
            "Epoch 883/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7065 - acc: 0.5452 - val_loss: 8.0718 - val_acc: 0.0692\n",
            "Epoch 884/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7066 - acc: 0.5452 - val_loss: 8.0720 - val_acc: 0.0694\n",
            "Epoch 885/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7072 - acc: 0.5459 - val_loss: 8.0751 - val_acc: 0.0694\n",
            "Epoch 886/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7077 - acc: 0.5449 - val_loss: 8.0746 - val_acc: 0.0692\n",
            "Epoch 887/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7131 - acc: 0.5428 - val_loss: 8.0817 - val_acc: 0.0694\n",
            "Epoch 888/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7281 - acc: 0.5410 - val_loss: 8.0402 - val_acc: 0.0703\n",
            "Epoch 889/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7282 - acc: 0.5404 - val_loss: 8.0541 - val_acc: 0.0694\n",
            "Epoch 890/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7298 - acc: 0.5385 - val_loss: 8.0632 - val_acc: 0.0712\n",
            "Epoch 891/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7312 - acc: 0.5380 - val_loss: 8.0578 - val_acc: 0.0709\n",
            "Epoch 892/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7405 - acc: 0.5363 - val_loss: 8.0358 - val_acc: 0.0692\n",
            "Epoch 893/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7451 - acc: 0.5333 - val_loss: 8.0641 - val_acc: 0.0680\n",
            "Epoch 894/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7487 - acc: 0.5330 - val_loss: 8.0622 - val_acc: 0.0703\n",
            "Epoch 895/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7431 - acc: 0.5360 - val_loss: 8.0479 - val_acc: 0.0726\n",
            "Epoch 896/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7360 - acc: 0.5379 - val_loss: 8.0619 - val_acc: 0.0694\n",
            "Epoch 897/1000\n",
            "1148/1148 [==============================] - 0s 307us/step - loss: 0.7293 - acc: 0.5406 - val_loss: 8.0441 - val_acc: 0.0689\n",
            "Epoch 898/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7266 - acc: 0.5392 - val_loss: 8.0532 - val_acc: 0.0703\n",
            "Epoch 899/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7237 - acc: 0.5414 - val_loss: 8.0450 - val_acc: 0.0706\n",
            "Epoch 900/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7224 - acc: 0.5422 - val_loss: 8.0407 - val_acc: 0.0709\n",
            "Epoch 901/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7164 - acc: 0.5435 - val_loss: 8.0593 - val_acc: 0.0706\n",
            "Epoch 902/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7143 - acc: 0.5442 - val_loss: 8.0551 - val_acc: 0.0683\n",
            "Epoch 903/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7144 - acc: 0.5444 - val_loss: 8.0518 - val_acc: 0.0697\n",
            "Epoch 904/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7101 - acc: 0.5447 - val_loss: 8.0761 - val_acc: 0.0694\n",
            "Epoch 905/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7090 - acc: 0.5453 - val_loss: 8.0663 - val_acc: 0.0709\n",
            "Epoch 906/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7086 - acc: 0.5462 - val_loss: 8.0687 - val_acc: 0.0680\n",
            "Epoch 907/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7086 - acc: 0.5464 - val_loss: 8.0744 - val_acc: 0.0689\n",
            "Epoch 908/1000\n",
            "1148/1148 [==============================] - 0s 329us/step - loss: 0.7079 - acc: 0.5453 - val_loss: 8.0788 - val_acc: 0.0683\n",
            "Epoch 909/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.7066 - acc: 0.5457 - val_loss: 8.0834 - val_acc: 0.0689\n",
            "Epoch 910/1000\n",
            "1148/1148 [==============================] - 0s 326us/step - loss: 0.7048 - acc: 0.5470 - val_loss: 8.0725 - val_acc: 0.0692\n",
            "Epoch 911/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7046 - acc: 0.5466 - val_loss: 8.0822 - val_acc: 0.0692\n",
            "Epoch 912/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.7062 - acc: 0.5460 - val_loss: 8.0816 - val_acc: 0.0671\n",
            "Epoch 913/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7037 - acc: 0.5461 - val_loss: 8.0877 - val_acc: 0.0671\n",
            "Epoch 914/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7027 - acc: 0.5471 - val_loss: 8.0931 - val_acc: 0.0683\n",
            "Epoch 915/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7037 - acc: 0.5470 - val_loss: 8.0887 - val_acc: 0.0697\n",
            "Epoch 916/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7095 - acc: 0.5462 - val_loss: 8.0812 - val_acc: 0.0677\n",
            "Epoch 917/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7060 - acc: 0.5454 - val_loss: 8.0896 - val_acc: 0.0689\n",
            "Epoch 918/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7091 - acc: 0.5462 - val_loss: 8.0877 - val_acc: 0.0677\n",
            "Epoch 919/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7074 - acc: 0.5433 - val_loss: 8.0857 - val_acc: 0.0697\n",
            "Epoch 920/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7069 - acc: 0.5462 - val_loss: 8.0860 - val_acc: 0.0683\n",
            "Epoch 921/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7063 - acc: 0.5445 - val_loss: 8.0974 - val_acc: 0.0689\n",
            "Epoch 922/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7093 - acc: 0.5452 - val_loss: 8.0868 - val_acc: 0.0694\n",
            "Epoch 923/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7076 - acc: 0.5453 - val_loss: 8.0897 - val_acc: 0.0706\n",
            "Epoch 924/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7067 - acc: 0.5454 - val_loss: 8.0957 - val_acc: 0.0686\n",
            "Epoch 925/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7060 - acc: 0.5462 - val_loss: 8.0890 - val_acc: 0.0709\n",
            "Epoch 926/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7089 - acc: 0.5460 - val_loss: 8.0974 - val_acc: 0.0697\n",
            "Epoch 927/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7072 - acc: 0.5439 - val_loss: 8.0977 - val_acc: 0.0709\n",
            "Epoch 928/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7078 - acc: 0.5451 - val_loss: 8.1026 - val_acc: 0.0700\n",
            "Epoch 929/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7094 - acc: 0.5441 - val_loss: 8.1043 - val_acc: 0.0692\n",
            "Epoch 930/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7065 - acc: 0.5449 - val_loss: 8.1116 - val_acc: 0.0686\n",
            "Epoch 931/1000\n",
            "1148/1148 [==============================] - 0s 332us/step - loss: 0.7074 - acc: 0.5443 - val_loss: 8.1141 - val_acc: 0.0680\n",
            "Epoch 932/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7032 - acc: 0.5460 - val_loss: 8.1160 - val_acc: 0.0677\n",
            "Epoch 933/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7035 - acc: 0.5456 - val_loss: 8.1197 - val_acc: 0.0666\n",
            "Epoch 934/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7014 - acc: 0.5465 - val_loss: 8.1096 - val_acc: 0.0686\n",
            "Epoch 935/1000\n",
            "1148/1148 [==============================] - 0s 311us/step - loss: 0.7027 - acc: 0.5463 - val_loss: 8.1167 - val_acc: 0.0657\n",
            "Epoch 936/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7013 - acc: 0.5451 - val_loss: 8.1186 - val_acc: 0.0660\n",
            "Epoch 937/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7023 - acc: 0.5453 - val_loss: 8.1213 - val_acc: 0.0654\n",
            "Epoch 938/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7028 - acc: 0.5467 - val_loss: 8.1142 - val_acc: 0.0683\n",
            "Epoch 939/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7009 - acc: 0.5476 - val_loss: 8.1202 - val_acc: 0.0668\n",
            "Epoch 940/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.7021 - acc: 0.5465 - val_loss: 8.1200 - val_acc: 0.0680\n",
            "Epoch 941/1000\n",
            "1148/1148 [==============================] - 0s 327us/step - loss: 0.7020 - acc: 0.5469 - val_loss: 8.1235 - val_acc: 0.0683\n",
            "Epoch 942/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7012 - acc: 0.5465 - val_loss: 8.1282 - val_acc: 0.0663\n",
            "Epoch 943/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7007 - acc: 0.5441 - val_loss: 8.1225 - val_acc: 0.0671\n",
            "Epoch 944/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7004 - acc: 0.5473 - val_loss: 8.1337 - val_acc: 0.0666\n",
            "Epoch 945/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7001 - acc: 0.5454 - val_loss: 8.1283 - val_acc: 0.0677\n",
            "Epoch 946/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7010 - acc: 0.5477 - val_loss: 8.1238 - val_acc: 0.0671\n",
            "Epoch 947/1000\n",
            "1148/1148 [==============================] - 0s 336us/step - loss: 0.6985 - acc: 0.5464 - val_loss: 8.1273 - val_acc: 0.0683\n",
            "Epoch 948/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7026 - acc: 0.5465 - val_loss: 8.1255 - val_acc: 0.0666\n",
            "Epoch 949/1000\n",
            "1148/1148 [==============================] - 0s 320us/step - loss: 0.7047 - acc: 0.5444 - val_loss: 8.1349 - val_acc: 0.0657\n",
            "Epoch 950/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7042 - acc: 0.5464 - val_loss: 8.1301 - val_acc: 0.0668\n",
            "Epoch 951/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7044 - acc: 0.5449 - val_loss: 8.1382 - val_acc: 0.0674\n",
            "Epoch 952/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7027 - acc: 0.5462 - val_loss: 8.1198 - val_acc: 0.0671\n",
            "Epoch 953/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7031 - acc: 0.5460 - val_loss: 8.1426 - val_acc: 0.0648\n",
            "Epoch 954/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7053 - acc: 0.5454 - val_loss: 8.1436 - val_acc: 0.0677\n",
            "Epoch 955/1000\n",
            "1148/1148 [==============================] - 0s 323us/step - loss: 0.7094 - acc: 0.5447 - val_loss: 8.1487 - val_acc: 0.0663\n",
            "Epoch 956/1000\n",
            "1148/1148 [==============================] - 0s 321us/step - loss: 0.7093 - acc: 0.5451 - val_loss: 8.1567 - val_acc: 0.0663\n",
            "Epoch 957/1000\n",
            "1148/1148 [==============================] - 0s 331us/step - loss: 0.7064 - acc: 0.5443 - val_loss: 8.1666 - val_acc: 0.0666\n",
            "Epoch 958/1000\n",
            "1148/1148 [==============================] - 0s 334us/step - loss: 0.7078 - acc: 0.5447 - val_loss: 8.1644 - val_acc: 0.0660\n",
            "Epoch 959/1000\n",
            "1148/1148 [==============================] - 0s 319us/step - loss: 0.7070 - acc: 0.5457 - val_loss: 8.1560 - val_acc: 0.0654\n",
            "Epoch 960/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7131 - acc: 0.5422 - val_loss: 8.1452 - val_acc: 0.0657\n",
            "Epoch 961/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7131 - acc: 0.5427 - val_loss: 8.1673 - val_acc: 0.0671\n",
            "Epoch 962/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7144 - acc: 0.5431 - val_loss: 8.1501 - val_acc: 0.0651\n",
            "Epoch 963/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.7103 - acc: 0.5433 - val_loss: 8.1427 - val_acc: 0.0657\n",
            "Epoch 964/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7139 - acc: 0.5428 - val_loss: 8.1800 - val_acc: 0.0651\n",
            "Epoch 965/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7172 - acc: 0.5425 - val_loss: 8.1619 - val_acc: 0.0674\n",
            "Epoch 966/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7275 - acc: 0.5389 - val_loss: 8.1724 - val_acc: 0.0660\n",
            "Epoch 967/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7295 - acc: 0.5385 - val_loss: 8.1414 - val_acc: 0.0677\n",
            "Epoch 968/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7305 - acc: 0.5391 - val_loss: 8.1592 - val_acc: 0.0671\n",
            "Epoch 969/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7365 - acc: 0.5370 - val_loss: 8.1578 - val_acc: 0.0663\n",
            "Epoch 970/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.7376 - acc: 0.5361 - val_loss: 8.1581 - val_acc: 0.0680\n",
            "Epoch 971/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7351 - acc: 0.5367 - val_loss: 8.1886 - val_acc: 0.0651\n",
            "Epoch 972/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7372 - acc: 0.5373 - val_loss: 8.1801 - val_acc: 0.0663\n",
            "Epoch 973/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.7312 - acc: 0.5382 - val_loss: 8.1585 - val_acc: 0.0666\n",
            "Epoch 974/1000\n",
            "1148/1148 [==============================] - 0s 310us/step - loss: 0.7280 - acc: 0.5391 - val_loss: 8.1829 - val_acc: 0.0663\n",
            "Epoch 975/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7204 - acc: 0.5417 - val_loss: 8.1647 - val_acc: 0.0657\n",
            "Epoch 976/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7167 - acc: 0.5427 - val_loss: 8.1720 - val_acc: 0.0668\n",
            "Epoch 977/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7125 - acc: 0.5449 - val_loss: 8.1715 - val_acc: 0.0668\n",
            "Epoch 978/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.7088 - acc: 0.5440 - val_loss: 8.1594 - val_acc: 0.0674\n",
            "Epoch 979/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.7053 - acc: 0.5438 - val_loss: 8.1656 - val_acc: 0.0666\n",
            "Epoch 980/1000\n",
            "1148/1148 [==============================] - 0s 309us/step - loss: 0.7057 - acc: 0.5470 - val_loss: 8.1684 - val_acc: 0.0668\n",
            "Epoch 981/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7052 - acc: 0.5459 - val_loss: 8.1698 - val_acc: 0.0671\n",
            "Epoch 982/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.7031 - acc: 0.5457 - val_loss: 8.1738 - val_acc: 0.0663\n",
            "Epoch 983/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.7035 - acc: 0.5457 - val_loss: 8.1780 - val_acc: 0.0671\n",
            "Epoch 984/1000\n",
            "1148/1148 [==============================] - 0s 314us/step - loss: 0.7013 - acc: 0.5470 - val_loss: 8.1737 - val_acc: 0.0674\n",
            "Epoch 985/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.6991 - acc: 0.5469 - val_loss: 8.1759 - val_acc: 0.0677\n",
            "Epoch 986/1000\n",
            "1148/1148 [==============================] - 0s 317us/step - loss: 0.6980 - acc: 0.5461 - val_loss: 8.1756 - val_acc: 0.0683\n",
            "Epoch 987/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.6959 - acc: 0.5481 - val_loss: 8.1889 - val_acc: 0.0671\n",
            "Epoch 988/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.6941 - acc: 0.5483 - val_loss: 8.1834 - val_acc: 0.0657\n",
            "Epoch 989/1000\n",
            "1148/1148 [==============================] - 0s 312us/step - loss: 0.6929 - acc: 0.5479 - val_loss: 8.1942 - val_acc: 0.0660\n",
            "Epoch 990/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.6936 - acc: 0.5482 - val_loss: 8.1911 - val_acc: 0.0654\n",
            "Epoch 991/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.6922 - acc: 0.5484 - val_loss: 8.1930 - val_acc: 0.0668\n",
            "Epoch 992/1000\n",
            "1148/1148 [==============================] - 0s 325us/step - loss: 0.6926 - acc: 0.5482 - val_loss: 8.1976 - val_acc: 0.0663\n",
            "Epoch 993/1000\n",
            "1148/1148 [==============================] - 0s 322us/step - loss: 0.6927 - acc: 0.5480 - val_loss: 8.1930 - val_acc: 0.0666\n",
            "Epoch 994/1000\n",
            "1148/1148 [==============================] - 0s 328us/step - loss: 0.6928 - acc: 0.5479 - val_loss: 8.1929 - val_acc: 0.0663\n",
            "Epoch 995/1000\n",
            "1148/1148 [==============================] - 0s 316us/step - loss: 0.6922 - acc: 0.5485 - val_loss: 8.1928 - val_acc: 0.0660\n",
            "Epoch 996/1000\n",
            "1148/1148 [==============================] - 0s 324us/step - loss: 0.6923 - acc: 0.5481 - val_loss: 8.1961 - val_acc: 0.0671\n",
            "Epoch 997/1000\n",
            "1148/1148 [==============================] - 0s 313us/step - loss: 0.6925 - acc: 0.5481 - val_loss: 8.1997 - val_acc: 0.0663\n",
            "Epoch 998/1000\n",
            "1148/1148 [==============================] - 0s 315us/step - loss: 0.6900 - acc: 0.5489 - val_loss: 8.1935 - val_acc: 0.0666\n",
            "Epoch 999/1000\n",
            "1148/1148 [==============================] - 0s 318us/step - loss: 0.6891 - acc: 0.5488 - val_loss: 8.2021 - val_acc: 0.0666\n",
            "Epoch 1000/1000\n",
            "1148/1148 [==============================] - 0s 308us/step - loss: 0.6889 - acc: 0.5496 - val_loss: 8.1997 - val_acc: 0.0668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alHpNiToHIDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "bebac82c-e185-44da-8266-b0382adf7a91"
      },
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='acc')\n",
        "plt.plot(r.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU1d3H8c/JZCMrWSGQQMIu+xJk\nU0AUC1ZBBavUWrVWtEVFa9sHtXVv1dpF62NpedRal4qKokhRKouiIkvCFoEAIWxJCAkhhOzLzHn+\nOJMhgQCBTHIzM7/365UXucvc+d255HvPnLsprTVCCCE8n5/VBQghhHAPCXQhhPASEuhCCOElJNCF\nEMJLSKALIYSX8LfqjWNjY3VycrJVby+EEB4pPT39qNY6rqlplgV6cnIyaWlpVr29EEJ4JKXUgTNN\nky4XIYTwEhLoQgjhJSTQhRDCS1jWh96U2tpacnJyqKqqsrqUdik4OJjExEQCAgKsLkUI0Q61q0DP\nyckhPDyc5ORklFJWl9OuaK0pKioiJyeHlJQUq8sRQrRD7arLpaqqipiYGAnzJiiliImJkW8vQogz\naleBDkiYn4V8NkKIs2l3gS6EEN5Ga43WmpKKWh76cBu5xytb5X3aVR+6EEK4Q/1zHvYWlhHkbyMh\nMhh/2+ntV7tDs/PwCTJySyiuqGHqwATiwoNwaE2Qvx+BNj9yiivZdLCYT7bmkX+iivjwYH49pS+J\nUSGEBTUdoQ6HZvHmXDTwy/e3YvNT2B0nnz0xsGskN4/q7vb1lkAXQlimuLyGsuo6MvNLyS4s485L\ne1BjdxAcYDvr6w4UlVNr1zi0ZltOCV/tKSQqJJDo0EDyjleycOOh017z0qxhXDOki2t4y6HjPLV0\nB+kHil3j/vDZrmZUfYJVmQUAhAf7M6ZHDAt+nOqaandofvqvjazeVegaN7pHNF0iO1BWXcf1wxOZ\n3L9TM97n/EmgN+Haa6/l0KFDVFVVMXfuXGbPns1nn33Gww8/jN1uJzY2lpUrV1JWVsa9995LWloa\nSikee+wxZsyYYXX5QrQ5rTWf7zjCOxsOcsuY7vTrHEGXjh1Om6+8uo5nPt3J4k25JHTsQFZBWaPp\nz3yaCYBSsOrBiaTEhjaaXlFTx8urs3h59d7zrvEPyzO5enACSinSDxRz4z++pc6hiQ8P4pbR3QkN\n8ufJpTuafO0lvWLJK6kku7C80fjSqjr+u+MIgx9fzh9mDmbKwATW7C50hfnMEYl8b0Bnrrgovk2O\ngbXbQH/ik+3syDvh1mX27xLBY9cMOOd8r732GtHR0VRWVjJy5EimT5/OnXfeyZo1a0hJSeHYsWMA\nPPXUU0RGRpKRkQFAcXHx2RYrRLtVVWtndWYBh4orSE2O5oUVewgJsPHCTUObbC0fLKpg7rub2Xzw\nOJP7d+LzHUdc0+rD7IlpA7h1bLJrfE5xBVNf/IrSqjoAV5jHhgVy7dCuLNmaR0FpNQBaw0ur9vDb\n7/dn15FSYkIDKa+xM++DbWTml9K1YweGJnXEoTWhQf7cNjaZ/+44QmVNHRU1djpFBDOmZwzZhWWM\n7RnLxv3H+MV7W1m8OZe48CBueXUDnSKCWHbfpcSEBblq7BUfhr+fYlSPGNbvKyI5JtS1Y7I7NEVl\n1cSGmS4Zf5sfG/Yd4/6Fm8krqeLRj7czoU888780O5tFd48hNTnajVvp3NptoFvpr3/9K4sXLwbg\n0KFDLFiwgPHjx7vO/46ONhtpxYoVLFy40PW6qKioti9WiFMcLavmRGUt4cEB1NodJEQGs2JnAYMT\nI+kUEQyYPl4/P8VXewqZu3ALx8prmlxWv99+RnJMCM9cP5gxPWMA+CbrKDe/st41T32YD0nqSE2d\ngzq7gz0FZTy2ZDtXD04gKiSQ45W1fLgpl9KqOoYkRvLL7/UlOSaUDoE2Yp2BesuY7vz9y2weu6Y/\nD3+YwYebcvlwU+5pNV0/rCu/v37QaTuagV0jT5t3pDNQO0UE839f7eN3/9npmvar7/VrFOYA4/uc\nvInh2J6xjabZ/BTxzs/PD9PavjglmrUPXc7Lq7N4fvkuhj31X6rrHNxzWa82D3Nox4HenJZ0a/ji\niy9YsWIF3377LSEhIUycOJGhQ4eSmZlpST1CnMuqzCMs3XqYhI7BfLgpl8Mlja9VOPWAHECgzY8a\nu6PRuA4BNgL9/bhmSAJTBya4Qnt/UQWz/m8d86b2Y+aIRB58b6vrNYvuHsOegjIuTommZ1yYa/z6\n7CJuXLCOd9MONeqXHtatI4t/Pq7J9egeE8oz1w8CYM6kXny4+fQwH9szhj/MHNzkAc6zCfT34/fX\nDeS6v60FTBfKjOFdz2sZZ3P7uGReWrWHqloH/RMiuHN8D7ct+3y020C3SklJCVFRUYSEhJCZmcm6\ndeuoqqpizZo17Nu3z9XlEh0dzeTJk3n55Zd54YUXANPlIq100Zq01vzl892s33eMlNjQJg/+1QsN\ntFFeYycuLIj8E41DvmGYf/CzsQzoEnFai/e9u8awKP0Q76XlAPDsp5k86+zjfvuno+gVH0aniOAm\nW6LDupm/g1MPMt7VzKDrGRfGR3PGkRAZzMMfZpCZX8oHPxtL58jgZr2+KcO6RRHo70dNnYPbx7n3\navSQQH+2PHolH23O5arBCUQEW3N7DlV/ek9bS01N1afeD33nzp1cdNFFltRTr7q6mmuvvZb9+/fT\nt29fjh8/zuOPP05lZSUPP/wwDoeD+Ph4Pv/8c8rKypgzZw7p6enYbDYee+wxrr/++latrz18RqLl\ntNY8v3wXf/tiL49d05+LU6IZ0OVkl8H9CzdT59C8NGuYK3jsDs2PXlnPt9lFpy3v9dtHsn7fMeZc\n1ovQQFuTYVVSWcux8hoCbIrEqBCyC8soLK1mVI+Yc9b6+2U7+b+v9gEwbUgX/jpr2DnX8eHFGXy0\nOZfHrumPUope8WEM72Ztg+fL3YV8sjWP3103kCD/s59J014ppdK11qlNTpNA9yzyGbV/qzML+PPn\nuzlcUkXfzmFc1DmC6UO7EhseSEKkOcD25//u4q+rshq9bsujk+kYEsg/v9nHE5+Ysy2uGtSZ28el\nEBsWxGtf7+PNdQdIiQ3l5xN7sizjMGHBAfzuuoGt3iJ0ODTr9hURFxZEcmwoAc3o8nA4NBW19jOe\nqy0uzNkCXT5pIVooI6eEp5buINDfhNzXWUdd045mVfNNVhGvfG1at4O6RpKRWwJA54hgnpkxiNv/\nuRGAddnH6BEX6gpzgGUZ+SzLyHcNB9gU/7nvEkIC/bkhNanV162en5867SBhc14jYd625NMW4gy0\n1uQer2RbTgkZuSXsP1rOfZf3xt9PkRQdwqaDxcSHB3HHvzZyvLKWmrqT/dIDukTwpx8MISTAn/HP\nr3aNrw/zkclRvHrbSCKCA9j99FQGP7Gcu99Kd8236beTWbjx4Gl90J/OHU9IoPzZiqbJ/wwhTlEf\n5M99totPtuY1mvbpd/mnzR8R7M+7s0czrFsUpVW1vLXuILePS3YdZFz/8OXU2h2EBwXwxrf7Gd49\ninG9TrZ2A/39uG1sCn//8uTFMtGhgQxN7NjofXrHh9ErPgwhzkQCXfi04vIaHl6cQXCAjSkDO7M7\nv5QXVu5pdJrfsG4duaRXLP9au58TzotiYsMCOVpWQ59OYTw7Y7DrrI7w4AB+NrFno/eoP/cb4N7L\nezdZx9zLe/P3L/fSIzaUV2413aOpydHcNDKJqwYlYPNTjU4LFKIpEujCq+0/Ws6JqlpKq+rQGlLi\nQvk04zDl1XZe+TrbddUiwGLnec/19+eYMrAz1w9PdE1/8Mq+rgty3K1DoI218yYRHRroatkH+vvx\n7IzBbn8v4b0k0IXX+nhLLnMXbjnnfHMv783YnjHcuGAdkR0CWH7/+DOe79waYV6vqXufCHE+JNCF\nx/tydyHdokMa3chpw75jrjAPD/JnYr94V3/4bWOT6RUfxqW9Y4kKDXSd8rf76anU2B1yZobwWPI/\ntwXCwsIoKys794zCLU5U1bIh+xhX9O/E6l0FrtP96k0b0oWhSR25rF88P/jHtwTa/PjDzMFcO8xc\n4v38zMGUVde57h1yqkB/P9eph0J4omYFulJqCvAiYANe0Vo/e8r024DngfqbL/yv1voVN9YpfJzW\nmuv/tpasgjL6dQ4nM7/0tHmWbM1jydY81y1QX799JGMbnE0SHGA75322hfBk5wx0pZQNeBmYDOQA\nG5VSS7TWp944+F2t9T1uq+zTeZCf4bbFAdB5EEx99oyT582bR1JSEnPmzAHg8ccfx9/fn9WrV1Nc\nXExtbS1PP/0006dPP+dblZWVMX369CZf98Ybb/DHP/4RpRSDBw/mzTff5MiRI9x9991kZ2cDMH/+\nfMaOHeuGlfZcG/Yd438+2Max8hpKKmtd4zPzSxnRPYofje5Gxw6BDE6M5K11B+nTKYwFX2Wz+eBx\n7rgkpVGYC+ELmtNCvxjI0lpnAyilFgLTgabvBO/BbrzxRu6//35XoL/33nssX76c++67j4iICI4e\nPcro0aOZNm3aOW/sExwczOLFi0973Y4dO3j66adZu3YtsbGxrnur33fffUyYMIHFixdjt9t9tivn\nRFUtr329jxdW7HGNC/T3w99PMeeyXkwf2oWk6JDTLj2fe4U5HXDqoAS01vJAbeGTmhPoXYGGt3TL\nAUY1Md8MpdR4YDfwgNb6tNvAKaVmA7MBunXrdvZ3PUtLurUMGzaMgoIC8vLyKCwsJCoqis6dO/PA\nAw+wZs0a/Pz8yM3N5ciRI3Tu3Pmsy9Ja8/DDD5/2ulWrVnHDDTcQG2taj/X3Vl+1ahVvvPEGADab\njcjI0+/t7K0y80/w0eY8EqM68JuPvms0LSzIn22PXdmsx5LVkzAXvspdB0U/Ad7RWlcrpe4C/gVM\nOnUmrfUCYAGYm3O56b3d6oYbbmDRokXk5+dz44038vbbb1NYWEh6ejoBAQEkJydTVVV1zuVc6Ot8\nQWWNneAAP5RSlFbVMuWFrxpN7xIZzNt3jkZrTefIYPz8FMF+0vctxLk055B+LtDwLkCJnDz4CYDW\nukhrXe0cfAUY4Z7y2t6NN97IwoULWbRoETfccAMlJSXEx8cTEBDA6tWrOXDgQLOWc6bXTZo0ifff\nf5+iInML1Poul8svv5z58+cDYLfbKSkpaYW1s97hkkpG/X4FY55ZxUsr9/D7ZY0fHPLQ1H6sfehy\nUmJD6REXJvctEeI8NOevZSPQWymVggnym4AfNpxBKZWgtT7sHJwG7MRDDRgwgNLSUrp27UpCQgI3\n33wz11xzDYMGDSI1NZV+/fo1azlnet2AAQN45JFHmDBhAjabjWHDhvH666/z4osvMnv2bF599VVs\nNhvz589nzJgxrbmqbcbh0KQdKOaf3+xz3QvlRFUdf/p8t2uehMhgbh+XzOzxPc+0GCHEOTTrfuhK\nqauAFzCnLb6mtf6dUupJIE1rvUQp9QwmyOuAY8DPtNZnfWab3A/9wnjiZ/TAu1tcl9UDXNo7lldv\nHcndb6VzvKKG9+8ei60Vr8AUwpu0+H7oWutlwLJTxj3a4PeHgIdaUqTwPl/uLuTW1za4ht+6YxQd\nQwJIig4h0N+P124baWF1Qngf6aBsoYyMDG655ZZG44KCgli/fv0ZXuGdtNYs2ZrHU0t3MK5XLLPH\n9+Cn/zJXcv5kXAqzx/do0fMghRDn1u4C3dPOIR40aBBbtpz7BlDuYNXjAs9Ga82db6SxYmeBa9zH\nW/L4eIu5b8pzMwZx48hznKIqhHCLdnXjiuDgYIqKitplcFlNa01RURHBwe2jlau15mBRBXe/le4K\n87Agf1Y9OME1T3CAH1cP7mJViUL4nHbVQk9MTCQnJ4fCwkKrS2mXgoODSUxMPPeMrUhrzbKMfDJy\nS1xP2OkQYGPBj0cwNKkj4cEBrPnVZZRU1jIo0XcujhKiPWhXgR4QEEBKSorVZYgzsDs0a/ceZc6/\nN7nG9YoP4727xhAdGuga1y0mxIryhPB57SrQRfu0Pa8EhwOu+d+vXeMGJ0byyFUXMapHjIWVCSEa\nkkAXZ1RWXcf/rspq9PBigJ9P7MmvpzTvAishRNuRQBdNKq+u4/El21mUnuMad1nfOJ66diCJUdKl\nIkR7JIEuTrPz8Amueelr6hyaHnGhrHpwotUlCSGaQQJdUFJRy58/38X6fcfIO17Jiao6AHrHh/Hi\nTcMsrk4I0VwS6D6uqKyaEU+vcA3fNDKJ8ho7P0hN5NLecRZWJoQ4XxLoPkxrzb3vbHYNv3/3GEYm\nR1tYkRCiJSTQfVBVrZ1NB4v5as9R1u4t4v4renP/FX2sLksI0UIS6D4m93glk//8JRU1dgBSu0dx\n9wS5B7kQ3qBd3ctFtK6aOgcPvrfFFeY9YkN5845RzX5WpxCifZMWug95P/0Q67KP8dyMQfwgNQmt\nwU8eLCGE15BA93IOh2ZLznHWZRfxh8920S06hJkjklBK4UF3KRZCNIMEuherqKnj6pe+JruwHIB+\nncN54ycXy+PehPBS0ofupersDh5Z/J0rzAGenzmE+Ij2cT91IYT7SQvdCxWWVjP22ZXU2jX9EyJY\n9LMxrM0qkvuTC+HlJNC9TGWNnTn/3kStXXPb2GQevLIPIYH+XNG/k9WlCSFamQS6F/ntR9/x5roD\nADx7/SBuulie5SmEL5FA9wJaa+b8exPLMvLpEGBj3tR+EuZC+CAJdA9XZ3fwlxW7WZaRT6DNj7Xz\nJhHV4HFwQgjfIYHuwXKKK7jkudUAjO0Zwz9uGUF4cIDFVQkhrCKnLXqoorJqZr+R7hp++YfDJcyF\n8HHSQvdAe46UMvkvawB45cepcgaLEAKQFrrHKSqrdoX5pb1jJcyFEC4S6B7E7tD87O1NAMwYnsib\nd4yyuCIhRHsiXS4eomE3yxUXxfOnHwyxuCIhRHsjLXQP8X9fZQPQJTKYuZfL04WEEKeTFroHmP/F\nXt5Ly2HakC78ddYwq8sRQrRTzWqhK6WmKKV2KaWylFLzzjLfDKWUVkqluq9E3/b88kye+yyT0T2i\nefq6gVaXI4Rox87ZQldK2YCXgclADrBRKbVEa73jlPnCgbnA+tYo1NfU2h08/GEG76fnEB0ayEuz\nhhMh55kLIc6iOS30i4EsrXW21roGWAhMb2K+p4DngCo31uezXv9mP++n5wDwn/suIS48yOKKhBDt\nXXMCvStwqMFwjnOci1JqOJCktf7P2RaklJqtlEpTSqUVFhaed7G+YlnGYX63bCc940LZ87upJER2\nsLokIYQHaPFZLkopP+DPwIPnmldrvUBrnaq1To2Li2vpW3ultVlH+bnzXPNfXtmXAJuciCSEaJ7m\nnOWSCyQ1GE50jqsXDgwEvlDmqcOdgSVKqWla6zR3FeoL7vn3JpZuOwzA8zMHM3VQgsUVCSE8SXMC\nfSPQWymVggnym4Af1k/UWpcAsfXDSqkvgF9KmJ+f7MIyV5h/PGccQ5I6WlyREMLTnPP7vNa6DrgH\nWA7sBN7TWm9XSj2plJrW2gX6gk8zDjPpT18CsOQeCXMhxIVp1oVFWutlwLJTxj16hnkntrws33G8\nooa5724hPNifv908nMGJEuZCiAsjV4pa7P20HGrqHLx1xyguTom2uhwhhAeTUygslFVQxjOf7mRi\n3zhGdI+yuhwhhIeTQLfQx1vMyUJ/vGEINj9lcTVCCE8ngW6R9APH+CA9h1EpMcSGyVWgQoiWk0C3\nwPLt+cyY/y15JVVMHdTZ6nKEEF5CAr2NlVXXcdeb5uHO3x+cwMwRiRZXJITwFnKWSxs6Vl7DyN+t\nAODJ6QP48ZhkawsSQngVaaG3oVkL1mF3aOZN7SdhLoRwOwn0NrJmdyG7jpQSExrI3RN6Wl2OEMIL\nSaC3geLyGp75NBOAd+8abXE1QghvJX3orczu0Ax76nMAfvP9i+gVH25xRUIIbyUt9Fa2KN08G6RH\nbCg/vbSHxdUIIbyZtNBb0f6j5fzPBxn0iAvlv/ePt7ocIYSXkxZ6K6p/8tBVAxPwlycPCSFamaRM\nK1mXXcSOwydIjgnh3st7WV2OEMIHSKC3khdX7KFTRBCfzh1PkL/N6nKEED5AAr0VvJ92iG+zi5g+\ntCsdAiXMhRBtQwLdzYrLa3j6PztJjOrAnInS1SKEaDtylosbaa15dMl2SqtqeWnWMCJDAqwuSQjh\nQ6SF7kZLtubxydY87ru8N+P7xFldjhDCx0igu0lVrZ25C7cAcO+k3hZXI4TwRRLobrJ022HX7/I4\nOSGEFSTQ3aCsuo4XVuwGzPNBhRDCCnJQ1A1e/WofOcWVzL95OFMHJVhdjhDCR0kLvYUKS6v5y4rd\npHaPkjAXQlhKAr0F7A7NA++aA6E3j+5mcTVCCF8ngd4CWw4V83XWUX71vb5cN0we9iyEsJYEegu8\nvvYANj/FTSOTrC5FCCEk0C/U4ZJKPtmax90TehATFmR1OUIIIYF+IbTW3PLqBgAm9+9scTVCCGFI\noF+ATQePk1VQxo9Gd2NIYqTV5QghBCCBft601vz2o+/oHBHMr6f0Qym5KlQI0T40K9CVUlOUUruU\nUllKqXlNTL9bKZWhlNqilPpaKdXf/aVaT2vNbz76jh2HT3D/Fb2JCJa7KQoh2o9zBrpSyga8DEwF\n+gOzmgjsf2utB2mthwJ/AP7s9krbgW05Jby9/iAA04Z2sbgaIYRorDkt9IuBLK11tta6BlgITG84\ng9b6RIPBUEC7r8T24720QwD88/aRhATKXROEEO1Lc1KpK3CowXAOMOrUmZRSc4BfAIHApKYWpJSa\nDcwG6NbNs66szCmu4J0NB5l1cTcu6xtvdTlCCHEatx0U1Vq/rLXuCfwP8JszzLNAa52qtU6Ni/Os\nB0C88e0BlFLcO0keKyeEaJ+aE+i5QMNLIROd485kIXBtS4pqb8qr63hnw0GmDOxMl44drC5HCCGa\n1JxA3wj0VkqlKKUCgZuAJQ1nUEo1fETP94E97ivReu+nHaK0qo6fjEuxuhQhhDijc/aha63rlFL3\nAMsBG/Ca1nq7UupJIE1rvQS4Ryl1BVALFAO3tmbRbamyxs7fvtjLyOQohnfraHU5QghxRs06VUNr\nvQxYdsq4Rxv8PtfNdbUbb67bT0FpNS/NGiYXEQkh2jW5UvQsau0OXvlqH+N6xTCqR4zV5QghxFlJ\noJ/Ff7cfoaC0WvrOhRAeQQL9DCpq6vj7l3tJiu7ARDnvXAjhASTQz+CFFXvIyC3h3km9sflJ37kQ\nov2TQD+DNbsLGZUSzQ9S5WlEQgjPIIHehK/3HCUzv5QpA+XhFUIIzyGBfgqtNU8t3UFKbCizLvas\n+80IIXybBPop0g8Us+tIKXeN70FwgM3qcoQQotkk0E/x0qoswoL8uWaI3O9cCOFZJNAbyC4s48vd\nhdxxSQqhQXK/cyGEZ5FAb2BVZgEAM0ckWlyJEEKcPwl0J601b607wODESJKiQ6wuRwghzpsEulNW\nQRn7iyrkzBYhhMeSQHdavNk8s2NCH896kpIQQtSTQMc8kej1tfuZ3L+TPJFICOGxJNCBj7fkUVFj\n5+4JPa0uRQghLpgEOvD2+gP06xwuTyQSQng0nw/0/JIqtuedYOaIRHkikRDCo/l8oM//IguAwYnS\nOhdCeDafDvTKGjvvbDjE4MRIhiZJoAshPJtPB/qmg8XU2B08MLkPgf4+/VEIIbyAT6fYt3uL8FOQ\n2j3K6lKEEKLFfDrQV2YWMKJ7FOHBAVaXIoQQLeazgb63sIydh0/wvQHyVCIhhHfw2UB/Py2HAJti\n+tCuVpcihBBu4bOBvnH/MQZ1jSQuPMjqUoQQwi18MtCrau1syznOyORoq0sRQgi38clA33roOLV2\nTaoEuhDCi/hkoK/aVYC/n2JkspyuKITwHj4X6FprlmzJY0KfODqGBFpdjhBCuI3PBfrewnIOl1Rx\n5YBOVpcihBBu5XOBnn7gGAAjukv/uRDCuzQr0JVSU5RSu5RSWUqpeU1M/4VSaodSaptSaqVSqrv7\nS3WP9APFRIUE0DMu1OpShBDCrc4Z6EopG/AyMBXoD8xSSvU/ZbbNQKrWejCwCPiDuwt1l7QDxYzo\nHiX3PhdCeJ3mtNAvBrK01tla6xpgITC94Qxa69Va6wrn4Dog0b1lusex8hqyC8ulu0UI4ZWaE+hd\ngUMNhnOc487kDuDTpiYopWYrpdKUUmmFhYXNr9JNPtqcC8AlvWLb/L2FEKK1ufWgqFLqR0Aq8HxT\n07XWC7TWqVrr1Li4OHe+dbOs2VNI7/gwBiVGtvl7CyFEa2tOoOcCSQ2GE53jGlFKXQE8AkzTWle7\npzz3cTg06QeK5epQIYTXak6gbwR6K6VSlFKBwE3AkoYzKKWGAf/AhHmB+8tsud0FpZRW1cnVoUII\nr3XOQNda1wH3AMuBncB7WuvtSqknlVLTnLM9D4QB7yultiillpxhcZbZuL8YgFQ5ICqE8FL+zZlJ\na70MWHbKuEcb/H6Fm+tyu/T9x4gPDyIpuoPVpQghRKvwmStFN+4vJjVZzj8XQngvnwj0wyWV5B6v\nlO4WIYRX84lAT6vvP5cDokIIL+YTgf71nqOEBNronxBhdSlCCNFqvD7Qa+ocLN6cy5X9O+Fv8/rV\nFUL4MK9PuOyjZdTYHVzWL97qUoQQolV5faDvyi8FoG/ncIsrEUKI1uUTge7vp+gRG2Z1KUII0aq8\nPtC35ZTQp1M4gf5ev6pCCB/n1SnncGi2HjrO0G4drS5FCCFanVcH+q4jpZRW1zE0SQJdCOH9vDrQ\nP9qci81PMUnOcBFC+ACvDfTjFTW8vnY/l/WNJzYsyOpyhBCi1XltoO/IO0F1nYMfje5mdSlCCNEm\nvDbQP9iUi1LQv4tc7i+E8A1eG+jb80oYnRJDfHiw1aUIIUSb8MpAdzg0B49VyNWhQgif4pWBviqz\ngIoaO8Pk/HMhhA/xykDfsP8YgTY/pgzsbHUpQgjRZrwu0LXWLN+eT2pyFEH+NqvLEUKINuN1gb7p\nYDEHiiq4fnii1aUIIUSb8rpA/3BTLsEB0t0ihPA9XhXo1XV2lm47zJQBnQkL8re6HCGEaFNeFeir\nMwsoqayV7hYhhE/ymkCvrGTDWAwAAA8tSURBVLHzjzXZxIcHMa5XrNXlCCFEm/OaQH/tm31sPnic\nR75/ETY/ZXU5QgjR5rwi0LXWvJd2iNE9opk+tKvV5QghhCW8ItAzcks4UFTBDOk7F0L4MK8I9ANF\nFQDyZCIhhE/zikA/Vl4DQFRooMWVCCGEdbwi0IvKa1AKokIk0IUQvqtZga6UmqKU2qWUylJKzWti\n+nil1CalVJ1Saqb7yzy7wtJqokIC5ewWIYRPO2egK6VswMvAVKA/MEsp1f+U2Q4CtwH/dneBzbEr\n/wS94sPOPENNOeSmw3cfQllh2xUmhBBtqDnXx18MZGmtswGUUguB6cCO+hm01vud0xytUONZVdXa\n2Z53gltGdz850mGHg9/C8kfg8BYIiYGKIjOt6wi4dSkEhrR1qUII0aqa0+XSFTjUYDjHOa5d+HJ3\nIdV1Di7tE3dy5MZX4PXvmzAHE+a9Jpvfc9Ph2STISW/7YoUQohW16R2slFKzgdkA3bp1c8syN+w7\nRnCAH+N6xpgRW9+FFY+b38MTYMhNMOwWiOlpxm1+C/7zS3hlEnTsDj94A2L7QMEOSEx1S01CCGGF\n5gR6LpDUYDjROe68aa0XAAsAUlNT9YUs41S5xZVcFpGH/9vXQ2AoZC41E2Z/AV2Gnf6CYT+CzoPh\nnVlw/AAsmHByWrexEBwJA6+HfleDfzD4ecWJQEIIH9CcQN8I9FZKpWCC/Cbgh61a1XnIOV7B7+zv\nQPZGMyIkFm7/FOL6nPlFCYPhF9vhs4dg3d9Ojj+41vy7+9OT40LjTL97dE/oOhxiekGXoe5fESGE\naKFzBrrWuk4pdQ+wHLABr2mttyulngTStNZLlFIjgcVAFHCNUuoJrfWAVq3c6bqiVxnCRug+Dq54\nAmJ7Q4dmXjE65RnzY6+D2nJYch/s+AjCOkNZvpmnvBB2f9b4dSN/CmPmQPaXMPxWacULIdoFpbVb\nej7OW2pqqk5LS2vRMkorawh/znkw9Ko/wsV3uqGyBg58C6WHzdky0Smmq2b930Ep0A1O6Lnhdeh3\nDdjkoRpCiNallErXWjd5wM/jEqgq+1s++XghYTFd6VBVyEQge8A99HB3mAN0H2P+HXj9yXFTnzVn\nyHxyHxz5zox7/7aT0/tMhdSfQGkejGgwXgghWpnHtdCPLHuOTht+7xoupCNB964nIsaCZ4jW1cD6\n+fD5o2efr9tYOJYNnQdC11TY9q7phw/uaLqKDq2DsgKI7w/Kz+wQwuJOvoe/3NJACGGcrYXucYGe\nfqCYW+ev4Nnvd2dC33g6RMThHxzaChWeB62heJ/5/Z0fQuFO9y6/Yzdzxk3PSTD+11CYCcnjzv26\n2irI22TOw+93NWSvNgd5Ow9yb31CiDbjVV0ulTV2ygghrmtPwuNjrC7HUAqie5jf71wFxw9CXF8o\nOQR7V5vx5QUQdxHs+S/YawENtkAz75CboDQfVjwG8QOgtuLkDgLMPABHd5s+fDAB3+9qCAozB2aD\nI2H3crAFmIO4h7eZ96w3/lew5vnGdV80DaKSodNASL7EfIuI7mGWVXII4i8ytdoCwOEw6+mwg7ab\n2ynUlJvlRDivM5ODw0JYyuNa6J/vOMKdb6TxyT2XMCgxshUqs1BNuTmXHqCuGg6ug8z/mAueEoaa\nwN+1rO3q6ZoK+dtg1F2w9qVzz5802pxhdHibOcVzwHVmZxHX1+wMdv/XdB917G4OKsf0hIpj5hvH\njiXQ50rzLaTimFleXRUEdDBdU0qZb0JlR8yOMCS6dde9vak6YS5+6zQAgsKtrkZYyKta6BU1dQB0\nCLRZXEkrCGzQdeQfBD0mmJ96s94x/370c0gYAmHxsONj2L7YjI/pDf2+D5GJpsVdftS01oMjzQHc\niEQY/0sT0qX5cHQPoKH4AHy3yCyj08CTB3vzM0wLvTlhDuZYQL3MvJMXeUWlmJ1Vw28MYHYYuQ12\n6uvnN+99ALoMN59Xz8vgmxehqsR8Y9n/NVQdN2ck5W8zxygCQyEgxHQ3Tfi1uVZBKfNTr6Yc1v/D\nLGfwjeabSn6GObhdWwkdomDfGrO8riOg8hj4BcCb10Llcfjhu+ZzDwqHoAiz7OpSsx3ttZD2KgyZ\nZY6R5G2GpIvNMsHswFY8BpveMMNXPA5pr5npV79gvjl9cMfJWmP7mOX0v9bsQAt2QNIo6DPF3MMI\nzK0uAoJPvqb0iHnf+H4QmQR+Z/n7qS6F/d+Y/1/fvAg9JkLq7eb03oZnch3ZYWrxszX+LM9Ea/Nz\nrm9yRXth7yrY9p75VtpzklnfmF6mEbB7uVnf0BjTrWgLMI2H2ko4kWfms/mbb5MN17NoL+RshKUP\nmM84aZR5bVRK43s72Wudn6Myf0fNWbd2wuNa6As3HGTehxl8M28SXTt2aIXKPJDWJpACOpz9D/Vs\naqvAz9/8IdSUO//4HCagNr8JeVtMOIXEmJ+l90N4F7hvMxz42lx4FRhqQmPlkzBxHrz7o8bvcdE1\nULATirLOr7aQWKg4emHrdTYp4yG2LxTtMWF14Gv3vwc0vjlce3HJL6Akx+xkU8abBoItyHQJbv8I\nSg42nj9lvHOHdgk46hrvvJUNLn3Q7Ag/f9Qc3xl8E6T/E1Y9ZQI2ZYLZqQGMuhvCOsHKJ8w1Hbuc\n13n0uRK++8DsVFvKFgT2avP76Dlm577/qzPPn3oH5GwwO/GGLvmF2aF17GZ2dPH9zWcW0aXp5VSX\nmW7QevZa02Vaf+sRN/Cqg6L//GYfT3yyg82/nSxPKPIkDc/Wyf8O7DXmjyQowoz/8nkT9LG9ze0Z\nju42IVKvtsocWwiONLdsCE8wLbhP7jMt5iufhiPbTYtywHWmdbb/K/OHPHCmaT1/88LZa7xomnnP\n4v1mp5b+z3Ov16UPmpZ1eQtvyzz4Jhh5B7zqvIlcj4mQ/YX5PSoFpv3V1Ka1+QZSWQxr/gRb3oKp\nz5sD3tWlJji0Nt11tRXmWEhL+HeAusqWLaMlpv/N7Dzqv730nGS2b9kRyN1sWs9Hd5ufs2l4sWBT\nwxfqomnm/8relSfHxfUzjZ8jO8BRa8bFDzA7gaoSCI01FyYmX3JBb+lVgb5gzV6e+TSTnU9OITjA\nC7tdROtKfx0KMmHgDNNdERJjuqV2fQozXjF/iPVyN5muF//gk99ewIRpXY0Jk7B4861j3xrTyquf\n50QefP0X2LAAHi023QzHD8GXz8HQm+GrP8LQH5rummG3nNzZ2etMCEenmOG6GvPeTXVT2GvN+0R1\nP30amGCvLDZdNw27DY5sNwfXj+wwXV5j7oFv/9d8FgNnwMg7nTsGh3nvoiyzfo46s6OsKTc73bB4\nWPNH069/eItpaQ+aCcERplujQ5RZty3/NuOuev7k8ux1kHKp6fo7lm0+49g+ZtqgmY23A5jPuLIY\nuo9tej0zFkG3UaaRUP+5Fe83t/Pod4055qKU6V6sqza3Bjl+yOwEi7LM51C013wjHXmnOe4TEAIr\nHzeNhAvVIdp0zzUUGg/f+z0MvuGCFulVgQ5QX7PyoL4t4aO0bt99sKf2M7uL1mbZ3nD19JEd5jjF\ngOtMX37VcdMFuXel+Wa18xPTfTXqLrPjCY6ETv3NzsVeZ47DZK00x7e0w3Q3teD/hNcFuhBC+Kqz\nBbqcOCyEEF5CAl0IIbyEBLoQQngJCXQhhPASEuhCCOElJNCFEMJLSKALIYSXkEAXQggvYdmFRUqp\nQuDABb48FmiFuzW1a7LOvkHW2Te0ZJ27a63jmppgWaC3hFIq7UxXSnkrWWffIOvsG1prnaXLRQgh\nvIQEuhBCeAlPDfQFVhdgAVln3yDr7BtaZZ09sg9dCCHE6Ty1hS6EEOIUEuhCCOElPC7QlVJTlFK7\nlFJZSql5VtfjLkqpJKXUaqXUDqXUdqXUXOf4aKXU50qpPc5/o5zjlVLqr87PYZtSari1a3BhlFI2\npdRmpdRS53CKUmq9c73eVUoFOscHOYeznNOTraz7QimlOiqlFimlMpVSO5VSY3xgGz/g/D/9nVLq\nHaVUsDduZ6XUa0qpAqXUdw3Gnfe2VUrd6px/j1Lq1vOpwaMCXSllA14GpgL9gVlKqf7WVuU2dcCD\nWuv+wGhgjnPd5gErtda9gZXOYTCfQW/nz2xgftuX7BZzgZ0Nhp8D/qK17gUUA3c4x98BFDvH/8U5\nnyd6EfhMa90PGIJZd6/dxkqprsB9QKrWeiBgA27CO7fz68CUU8ad17ZVSkUDjwGjgIuBx+p3As2i\ntfaYH2AMsLzB8EPAQ1bX1Urr+jEwGdgFJDjHJQC7nL//A5jVYH7XfJ7yAyQ6/5NPApYCCnP1nP+p\n2xtYDoxx/u7vnE9ZvQ7nub6RwL5T6/bybdwVOAREO7fbUuB73rqdgWTguwvdtsAs4B8Nxjea71w/\nHtVC5+R/jno5znFexfk1cxiwHuiktT7snJQPdHL+7g2fxQvArwGHczgGOK61rnMON1wn1/o6p5c4\n5/ckKUAh8E9nN9MrSqlQvHgba61zgT8CB4HDmO2Wjndv54bOd9u2aJt7WqB7PaVUGPABcL/W+kTD\nadrssr3iPFOl1NVAgdY63epa2pA/MByYr7UeBpRz8is44F3bGMDZXTAdszPrAoRyereET2iLbetp\ngZ4LJDUYTnSO8wpKqQBMmL+ttf7QOfqIUirBOT0BKHCO9/TPYhwwTSm1H1iI6XZ5EeiolPJ3ztNw\nnVzr65weCRS1ZcFukAPkaK3XO4cXYQLeW7cxwBXAPq11oda6FvgQs+29eTs3dL7btkXb3NMCfSPQ\n23mEPBBzcGWJxTW5hVJKAa8CO7XWf24waQlQf6T7Vkzfev34HzuPlo8GShp8tWv3tNYPaa0TtdbJ\nmO24Smt9M7AamOmc7dT1rf8cZjrn96iWrNY6HziklOrrHHU5sAMv3cZOB4HRSqkQ5//x+nX22u18\nivPdtsuBK5VSUc5vN1c6xzWP1QcRLuCgw1XAbmAv8IjV9bhxvS7BfB3bBmxx/lyF6T9cCewBVgDR\nzvkV5oyfvUAG5iwCy9fjAtd9IrDU+XsPYAOQBbwPBDnHBzuHs5zTe1hd9wWu61AgzbmdPwKivH0b\nA08AmcB3wJtAkDduZ+AdzHGCWsy3sTsuZNsCP3GufxZw+/nUIJf+CyGEl/C0LhchhBBnIIEuhBBe\nQgJdCCG8hAS6EEJ4CQl0IYTwEhLoQgjhJSTQhRDCS/w/K0UEzCGntgwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xohWUZbHFgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a sampling model\n",
        "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
        "x = embedding_layer(input2)\n",
        "x, h, c = lstm(x, initial_state=[initial_h, initial_c]) # now we need states to feed back in\n",
        "output2 = dense(x)\n",
        "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])\n",
        "\n",
        "\n",
        "# reverse word2idx dictionary to get back words\n",
        "# during prediction\n",
        "idx2word = {v:k for k, v in word2idx.items()}\n",
        "\n",
        "\n",
        "def sample_line():\n",
        "  # initial inputs\n",
        "  np_input = np.array([[ word2idx['<sos>'] ]])\n",
        "  h = np.zeros((1, LATENT_DIM))\n",
        "  c = np.zeros((1, LATENT_DIM))\n",
        "\n",
        "  # so we know when to quit\n",
        "  eos = word2idx['<eos>']\n",
        "\n",
        "  # store the output here\n",
        "  output_sentence = []\n",
        "\n",
        "  for _ in range(max_sequence_length):\n",
        "    o, h, c = sampling_model.predict([np_input, h, c])\n",
        "\n",
        "    # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
        "    # idx = np.argmax(o[0,0])\n",
        "    probs = o[0,0]\n",
        "    if np.argmax(probs) == 0:\n",
        "      print(\"wtf\")\n",
        "    probs[0] = 0\n",
        "    probs /= probs.sum()\n",
        "    idx = np.random.choice(len(probs), p=probs)\n",
        "    if idx == eos:\n",
        "      break\n",
        "\n",
        "    # accuulate output\n",
        "    output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
        "\n",
        "    # make the next input into model\n",
        "    np_input[0,0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRMVCb8MHqe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1d0057b0-f420-4b31-d3ff-b1fec832939d"
      },
      "source": [
        "# generate a 4 line poem\n",
        "while True:\n",
        "  for _ in range(4):\n",
        "    print(sample_line())\n",
        "\n",
        "  ans = input(\"---generate another? [Y/n]---\")\n",
        "  if ans and ans[0].lower().startswith('n'):\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "had spilled them near the window, toward the light\n",
            "with the dead race of the great auk!'\n",
            "and jupiter.\n",
            "that there's something the dead are keeping back?\n",
            "---generate another? [Y/n]---n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ81xONzU-mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}